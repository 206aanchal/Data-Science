{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem- 1)"
      ],
      "metadata": {
        "id": "9RaWK1NgbZTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict turbine energy yield (TEY) using ambient variables as features.\n",
        "\n",
        "The dataset contains 36733 instances of 11 sensor measures aggregated over one hour (by means of average or sum) from a gas turbine.\n",
        "\n",
        "The Dataset includes gas turbine parameters (such as Turbine Inlet Temperature and Compressor Discharge pressure) in addition to the ambient variables.\n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "The explanations of sensor measurements and their brief statistics are given below.\n",
        "\n",
        "Variable (Abbr.) Unit Min Max Mean\n",
        "\n",
        "Ambient temperature (AT) C â€“6.23 37.10 17.71\n",
        "\n",
        "Ambient pressure (AP) mbar 985.85 1036.56 1013.07\n",
        "\n",
        "Ambient humidity (AH) (%) 24.08 100.20 77.87\n",
        "\n",
        "Air filter difference pressure (AFDP) mbar 2.09 7.61 3.93\n",
        "\n",
        "Gas turbine exhaust pressure (GTEP) mbar 17.70 40.72 25.56\n",
        "\n",
        "Turbine inlet temperature (TIT) C 1000.85 1100.89 1081.43\n",
        "\n",
        "Turbine after temperature (TAT) C 511.04 550.61 546.16\n",
        "\n",
        "Compressor discharge pressure (CDP) mbar 9.85 15.16 12.06\n",
        "\n",
        "Turbine energy yield (TEY) MWH 100.02 179.50 133.51\n",
        "\n",
        "Carbon monoxide (CO) mg/m3 0.00 44.10 2.37\n",
        "\n",
        "Nitrogen oxides (NOx) mg/m3 25.90 119.91 65.29"
      ],
      "metadata": {
        "id": "tWxzqcsJdDfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import keras\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "6q34PUTtbtDL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "fy58cZj1ce0c",
        "outputId": "438fc9ba-c342-48a0-b106-ca66ab89e1b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f6620dff-f9d6-492c-badd-7fb8f2ac5b64\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f6620dff-f9d6-492c-badd-7fb8f2ac5b64\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving gas_turbines.csv to gas_turbines.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gas_turbs= pd.read_csv('gas_turbines.csv')\n",
        "gas_turbs"
      ],
      "metadata": {
        "id": "K0kHlJZOdmcK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "528d3ddd-ed8f-4ae4-9528-e42e2815cb1d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
              "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
              "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
              "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
              "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
              "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
              "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
              "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
              "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
              "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
              "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
              "\n",
              "           CO     NOX  \n",
              "0      3.1547  82.722  \n",
              "1      3.2363  82.776  \n",
              "2      3.2012  82.468  \n",
              "3      3.1923  82.670  \n",
              "4      3.2484  82.311  \n",
              "...       ...     ...  \n",
              "15034  4.5186  79.559  \n",
              "15035  4.8470  79.917  \n",
              "15036  7.9632  90.912  \n",
              "15037  6.2494  93.227  \n",
              "15038  4.9816  92.498  \n",
              "\n",
              "[15039 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ba74e18-6d68-46c0-aae3-a6d0a4c6ba3e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AT</th>\n",
              "      <th>AP</th>\n",
              "      <th>AH</th>\n",
              "      <th>AFDP</th>\n",
              "      <th>GTEP</th>\n",
              "      <th>TIT</th>\n",
              "      <th>TAT</th>\n",
              "      <th>TEY</th>\n",
              "      <th>CDP</th>\n",
              "      <th>CO</th>\n",
              "      <th>NOX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.8594</td>\n",
              "      <td>1007.9</td>\n",
              "      <td>96.799</td>\n",
              "      <td>3.5000</td>\n",
              "      <td>19.663</td>\n",
              "      <td>1059.2</td>\n",
              "      <td>550.00</td>\n",
              "      <td>114.70</td>\n",
              "      <td>10.605</td>\n",
              "      <td>3.1547</td>\n",
              "      <td>82.722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.7850</td>\n",
              "      <td>1008.4</td>\n",
              "      <td>97.118</td>\n",
              "      <td>3.4998</td>\n",
              "      <td>19.728</td>\n",
              "      <td>1059.3</td>\n",
              "      <td>550.00</td>\n",
              "      <td>114.72</td>\n",
              "      <td>10.598</td>\n",
              "      <td>3.2363</td>\n",
              "      <td>82.776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.8977</td>\n",
              "      <td>1008.8</td>\n",
              "      <td>95.939</td>\n",
              "      <td>3.4824</td>\n",
              "      <td>19.779</td>\n",
              "      <td>1059.4</td>\n",
              "      <td>549.87</td>\n",
              "      <td>114.71</td>\n",
              "      <td>10.601</td>\n",
              "      <td>3.2012</td>\n",
              "      <td>82.468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.0569</td>\n",
              "      <td>1009.2</td>\n",
              "      <td>95.249</td>\n",
              "      <td>3.4805</td>\n",
              "      <td>19.792</td>\n",
              "      <td>1059.6</td>\n",
              "      <td>549.99</td>\n",
              "      <td>114.72</td>\n",
              "      <td>10.606</td>\n",
              "      <td>3.1923</td>\n",
              "      <td>82.670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.3978</td>\n",
              "      <td>1009.7</td>\n",
              "      <td>95.150</td>\n",
              "      <td>3.4976</td>\n",
              "      <td>19.765</td>\n",
              "      <td>1059.7</td>\n",
              "      <td>549.98</td>\n",
              "      <td>114.72</td>\n",
              "      <td>10.612</td>\n",
              "      <td>3.2484</td>\n",
              "      <td>82.311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15034</th>\n",
              "      <td>9.0301</td>\n",
              "      <td>1005.6</td>\n",
              "      <td>98.460</td>\n",
              "      <td>3.5421</td>\n",
              "      <td>19.164</td>\n",
              "      <td>1049.7</td>\n",
              "      <td>546.21</td>\n",
              "      <td>111.61</td>\n",
              "      <td>10.400</td>\n",
              "      <td>4.5186</td>\n",
              "      <td>79.559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15035</th>\n",
              "      <td>7.8879</td>\n",
              "      <td>1005.9</td>\n",
              "      <td>99.093</td>\n",
              "      <td>3.5059</td>\n",
              "      <td>19.414</td>\n",
              "      <td>1046.3</td>\n",
              "      <td>543.22</td>\n",
              "      <td>111.78</td>\n",
              "      <td>10.433</td>\n",
              "      <td>4.8470</td>\n",
              "      <td>79.917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15036</th>\n",
              "      <td>7.2647</td>\n",
              "      <td>1006.3</td>\n",
              "      <td>99.496</td>\n",
              "      <td>3.4770</td>\n",
              "      <td>19.530</td>\n",
              "      <td>1037.7</td>\n",
              "      <td>537.32</td>\n",
              "      <td>110.19</td>\n",
              "      <td>10.483</td>\n",
              "      <td>7.9632</td>\n",
              "      <td>90.912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15037</th>\n",
              "      <td>7.0060</td>\n",
              "      <td>1006.8</td>\n",
              "      <td>99.008</td>\n",
              "      <td>3.4486</td>\n",
              "      <td>19.377</td>\n",
              "      <td>1043.2</td>\n",
              "      <td>541.24</td>\n",
              "      <td>110.74</td>\n",
              "      <td>10.533</td>\n",
              "      <td>6.2494</td>\n",
              "      <td>93.227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15038</th>\n",
              "      <td>6.9279</td>\n",
              "      <td>1007.2</td>\n",
              "      <td>97.533</td>\n",
              "      <td>3.4275</td>\n",
              "      <td>19.306</td>\n",
              "      <td>1049.9</td>\n",
              "      <td>545.85</td>\n",
              "      <td>111.58</td>\n",
              "      <td>10.583</td>\n",
              "      <td>4.9816</td>\n",
              "      <td>92.498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15039 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ba74e18-6d68-46c0-aae3-a6d0a4c6ba3e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ba74e18-6d68-46c0-aae3-a6d0a4c6ba3e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ba74e18-6d68-46c0-aae3-a6d0a4c6ba3e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "KkaB_O-Tnw88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gas_turbs.info()"
      ],
      "metadata": {
        "id": "ZdueADuVcfBF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6503c289-c1c2-408f-a000-77b9b2c88336"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15039 entries, 0 to 15038\n",
            "Data columns (total 11 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   AT      15039 non-null  float64\n",
            " 1   AP      15039 non-null  float64\n",
            " 2   AH      15039 non-null  float64\n",
            " 3   AFDP    15039 non-null  float64\n",
            " 4   GTEP    15039 non-null  float64\n",
            " 5   TIT     15039 non-null  float64\n",
            " 6   TAT     15039 non-null  float64\n",
            " 7   TEY     15039 non-null  float64\n",
            " 8   CDP     15039 non-null  float64\n",
            " 9   CO      15039 non-null  float64\n",
            " 10  NOX     15039 non-null  float64\n",
            "dtypes: float64(11)\n",
            "memory usage: 1.3 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gas_turbs.duplicated().value_counts()"
      ],
      "metadata": {
        "id": "UNT31aOWfzmP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "978cf506-7b4e-40db-adfb-096a96c57eed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    15039\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gas_turbs.describe()"
      ],
      "metadata": {
        "id": "nLjLPkkccfHT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "4b7f58bf-8ed4-431e-973f-b3d24085f9fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 AT           AP            AH          AFDP          GTEP  \\\n",
              "count  15039.000000  15039.00000  15039.000000  15039.000000  15039.000000   \n",
              "mean      17.764381   1013.19924     79.124174      4.200294     25.419061   \n",
              "std        7.574323      6.41076     13.793439      0.760197      4.173916   \n",
              "min        0.522300    985.85000     30.344000      2.087400     17.878000   \n",
              "25%       11.408000   1008.90000     69.750000      3.723900     23.294000   \n",
              "50%       18.186000   1012.80000     82.266000      4.186200     25.082000   \n",
              "75%       23.862500   1016.90000     90.043500      4.550900     27.184000   \n",
              "max       34.929000   1034.20000    100.200000      7.610600     37.402000   \n",
              "\n",
              "                TIT           TAT           TEY           CDP            CO  \\\n",
              "count  15039.000000  15039.000000  15039.000000  15039.000000  15039.000000   \n",
              "mean    1083.798770    545.396183    134.188464     12.102353      1.972499   \n",
              "std       16.527806      7.866803     15.829717      1.103196      2.222206   \n",
              "min     1000.800000    512.450000    100.170000      9.904400      0.000388   \n",
              "25%     1079.600000    542.170000    127.985000     11.622000      0.858055   \n",
              "50%     1088.700000    549.890000    133.780000     12.025000      1.390200   \n",
              "75%     1096.000000    550.060000    140.895000     12.578000      2.160400   \n",
              "max     1100.800000    550.610000    174.610000     15.081000     44.103000   \n",
              "\n",
              "                NOX  \n",
              "count  15039.000000  \n",
              "mean      68.190934  \n",
              "std       10.470586  \n",
              "min       27.765000  \n",
              "25%       61.303500  \n",
              "50%       66.601000  \n",
              "75%       73.935500  \n",
              "max      119.890000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0df0523f-d157-4859-9743-9f1a3a10d5bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AT</th>\n",
              "      <th>AP</th>\n",
              "      <th>AH</th>\n",
              "      <th>AFDP</th>\n",
              "      <th>GTEP</th>\n",
              "      <th>TIT</th>\n",
              "      <th>TAT</th>\n",
              "      <th>TEY</th>\n",
              "      <th>CDP</th>\n",
              "      <th>CO</th>\n",
              "      <th>NOX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.00000</td>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>17.764381</td>\n",
              "      <td>1013.19924</td>\n",
              "      <td>79.124174</td>\n",
              "      <td>4.200294</td>\n",
              "      <td>25.419061</td>\n",
              "      <td>1083.798770</td>\n",
              "      <td>545.396183</td>\n",
              "      <td>134.188464</td>\n",
              "      <td>12.102353</td>\n",
              "      <td>1.972499</td>\n",
              "      <td>68.190934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.574323</td>\n",
              "      <td>6.41076</td>\n",
              "      <td>13.793439</td>\n",
              "      <td>0.760197</td>\n",
              "      <td>4.173916</td>\n",
              "      <td>16.527806</td>\n",
              "      <td>7.866803</td>\n",
              "      <td>15.829717</td>\n",
              "      <td>1.103196</td>\n",
              "      <td>2.222206</td>\n",
              "      <td>10.470586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.522300</td>\n",
              "      <td>985.85000</td>\n",
              "      <td>30.344000</td>\n",
              "      <td>2.087400</td>\n",
              "      <td>17.878000</td>\n",
              "      <td>1000.800000</td>\n",
              "      <td>512.450000</td>\n",
              "      <td>100.170000</td>\n",
              "      <td>9.904400</td>\n",
              "      <td>0.000388</td>\n",
              "      <td>27.765000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.408000</td>\n",
              "      <td>1008.90000</td>\n",
              "      <td>69.750000</td>\n",
              "      <td>3.723900</td>\n",
              "      <td>23.294000</td>\n",
              "      <td>1079.600000</td>\n",
              "      <td>542.170000</td>\n",
              "      <td>127.985000</td>\n",
              "      <td>11.622000</td>\n",
              "      <td>0.858055</td>\n",
              "      <td>61.303500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>18.186000</td>\n",
              "      <td>1012.80000</td>\n",
              "      <td>82.266000</td>\n",
              "      <td>4.186200</td>\n",
              "      <td>25.082000</td>\n",
              "      <td>1088.700000</td>\n",
              "      <td>549.890000</td>\n",
              "      <td>133.780000</td>\n",
              "      <td>12.025000</td>\n",
              "      <td>1.390200</td>\n",
              "      <td>66.601000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>23.862500</td>\n",
              "      <td>1016.90000</td>\n",
              "      <td>90.043500</td>\n",
              "      <td>4.550900</td>\n",
              "      <td>27.184000</td>\n",
              "      <td>1096.000000</td>\n",
              "      <td>550.060000</td>\n",
              "      <td>140.895000</td>\n",
              "      <td>12.578000</td>\n",
              "      <td>2.160400</td>\n",
              "      <td>73.935500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>34.929000</td>\n",
              "      <td>1034.20000</td>\n",
              "      <td>100.200000</td>\n",
              "      <td>7.610600</td>\n",
              "      <td>37.402000</td>\n",
              "      <td>1100.800000</td>\n",
              "      <td>550.610000</td>\n",
              "      <td>174.610000</td>\n",
              "      <td>15.081000</td>\n",
              "      <td>44.103000</td>\n",
              "      <td>119.890000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0df0523f-d157-4859-9743-9f1a3a10d5bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0df0523f-d157-4859-9743-9f1a3a10d5bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0df0523f-d157-4859-9743-9f1a3a10d5bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standardizing Data"
      ],
      "metadata": {
        "id": "t3gUMVHvf_Vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "std=StandardScaler()\n",
        "gas_turbstd=gas_turbs.copy()\n",
        "std.fit_transform(gas_turbstd)"
      ],
      "metadata": {
        "id": "fee0WR8FcfM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a895162-3a68-4ace-a820-bd28592beec2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.4397781 , -0.82664395,  1.28143632, ..., -1.35733078,\n",
              "         0.53201195,  1.3878449 ],\n",
              "       [-1.44960109, -0.74864748,  1.30456402, ..., -1.36367619,\n",
              "         0.56873344,  1.39300237],\n",
              "       [-1.43472138, -0.68625031,  1.21908576, ..., -1.36095673,\n",
              "         0.5529378 ,  1.36358566],\n",
              "       ...,\n",
              "       [-1.38626659, -1.07623263,  1.47697056, ..., -1.46792219,\n",
              "         2.69592467,  2.17006209],\n",
              "       [-1.42042259, -0.99823616,  1.44159024, ..., -1.42259784,\n",
              "         1.9246834 ,  2.391165  ],\n",
              "       [-1.43073409, -0.93583899,  1.33465179, ..., -1.37727349,\n",
              "         1.35415028,  2.32153907]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gas_turbstd=pd.DataFrame(std.fit_transform(gas_turbstd),columns=gas_turbs.columns)\n",
        "gas_turbstd"
      ],
      "metadata": {
        "id": "gmskgPSfcfPt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "c30b135a-f72c-4f63-d301-137f23a81f1a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             AT        AP        AH      AFDP      GTEP       TIT       TAT  \\\n",
              "0     -1.439778 -0.826644  1.281436 -0.921232 -1.379101 -1.488376  0.585240   \n",
              "1     -1.449601 -0.748647  1.304564 -0.921495 -1.363528 -1.482325  0.585240   \n",
              "2     -1.434721 -0.686250  1.219086 -0.944385 -1.351309 -1.476275  0.568715   \n",
              "3     -1.413702 -0.623853  1.169060 -0.946884 -1.348194 -1.464173  0.583969   \n",
              "4     -1.368693 -0.545857  1.161883 -0.924389 -1.354663 -1.458123  0.582698   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "15034 -1.153182 -1.185428  1.401860 -0.865850 -1.498657 -2.063184  0.103453   \n",
              "15035 -1.303986 -1.138630  1.447753 -0.913470 -1.438759 -2.268905 -0.276638   \n",
              "15036 -1.386267 -1.076233  1.476971 -0.951488 -1.410967 -2.789257 -1.026650   \n",
              "15037 -1.420423 -0.998236  1.441590 -0.988848 -1.447624 -2.456474 -0.528337   \n",
              "15038 -1.430734 -0.935839  1.334652 -1.016605 -1.464635 -2.051083  0.057689   \n",
              "\n",
              "            TEY       CDP        CO       NOX  \n",
              "0     -1.231172 -1.357331  0.532012  1.387845  \n",
              "1     -1.229909 -1.363676  0.568733  1.393002  \n",
              "2     -1.230541 -1.360957  0.552938  1.363586  \n",
              "3     -1.229909 -1.356424  0.548933  1.382878  \n",
              "4     -1.229909 -1.350985  0.574179  1.348591  \n",
              "...         ...       ...       ...       ...  \n",
              "15034 -1.426381 -1.543161  1.145792  1.085751  \n",
              "15035 -1.415642 -1.513247  1.293578  1.119943  \n",
              "15036 -1.516089 -1.467922  2.695925  2.170062  \n",
              "15037 -1.481343 -1.422598  1.924683  2.391165  \n",
              "15038 -1.428277 -1.377273  1.354150  2.321539  \n",
              "\n",
              "[15039 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df17851e-12a8-4ab1-8079-da117db557d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AT</th>\n",
              "      <th>AP</th>\n",
              "      <th>AH</th>\n",
              "      <th>AFDP</th>\n",
              "      <th>GTEP</th>\n",
              "      <th>TIT</th>\n",
              "      <th>TAT</th>\n",
              "      <th>TEY</th>\n",
              "      <th>CDP</th>\n",
              "      <th>CO</th>\n",
              "      <th>NOX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.439778</td>\n",
              "      <td>-0.826644</td>\n",
              "      <td>1.281436</td>\n",
              "      <td>-0.921232</td>\n",
              "      <td>-1.379101</td>\n",
              "      <td>-1.488376</td>\n",
              "      <td>0.585240</td>\n",
              "      <td>-1.231172</td>\n",
              "      <td>-1.357331</td>\n",
              "      <td>0.532012</td>\n",
              "      <td>1.387845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.449601</td>\n",
              "      <td>-0.748647</td>\n",
              "      <td>1.304564</td>\n",
              "      <td>-0.921495</td>\n",
              "      <td>-1.363528</td>\n",
              "      <td>-1.482325</td>\n",
              "      <td>0.585240</td>\n",
              "      <td>-1.229909</td>\n",
              "      <td>-1.363676</td>\n",
              "      <td>0.568733</td>\n",
              "      <td>1.393002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.434721</td>\n",
              "      <td>-0.686250</td>\n",
              "      <td>1.219086</td>\n",
              "      <td>-0.944385</td>\n",
              "      <td>-1.351309</td>\n",
              "      <td>-1.476275</td>\n",
              "      <td>0.568715</td>\n",
              "      <td>-1.230541</td>\n",
              "      <td>-1.360957</td>\n",
              "      <td>0.552938</td>\n",
              "      <td>1.363586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.413702</td>\n",
              "      <td>-0.623853</td>\n",
              "      <td>1.169060</td>\n",
              "      <td>-0.946884</td>\n",
              "      <td>-1.348194</td>\n",
              "      <td>-1.464173</td>\n",
              "      <td>0.583969</td>\n",
              "      <td>-1.229909</td>\n",
              "      <td>-1.356424</td>\n",
              "      <td>0.548933</td>\n",
              "      <td>1.382878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.368693</td>\n",
              "      <td>-0.545857</td>\n",
              "      <td>1.161883</td>\n",
              "      <td>-0.924389</td>\n",
              "      <td>-1.354663</td>\n",
              "      <td>-1.458123</td>\n",
              "      <td>0.582698</td>\n",
              "      <td>-1.229909</td>\n",
              "      <td>-1.350985</td>\n",
              "      <td>0.574179</td>\n",
              "      <td>1.348591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15034</th>\n",
              "      <td>-1.153182</td>\n",
              "      <td>-1.185428</td>\n",
              "      <td>1.401860</td>\n",
              "      <td>-0.865850</td>\n",
              "      <td>-1.498657</td>\n",
              "      <td>-2.063184</td>\n",
              "      <td>0.103453</td>\n",
              "      <td>-1.426381</td>\n",
              "      <td>-1.543161</td>\n",
              "      <td>1.145792</td>\n",
              "      <td>1.085751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15035</th>\n",
              "      <td>-1.303986</td>\n",
              "      <td>-1.138630</td>\n",
              "      <td>1.447753</td>\n",
              "      <td>-0.913470</td>\n",
              "      <td>-1.438759</td>\n",
              "      <td>-2.268905</td>\n",
              "      <td>-0.276638</td>\n",
              "      <td>-1.415642</td>\n",
              "      <td>-1.513247</td>\n",
              "      <td>1.293578</td>\n",
              "      <td>1.119943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15036</th>\n",
              "      <td>-1.386267</td>\n",
              "      <td>-1.076233</td>\n",
              "      <td>1.476971</td>\n",
              "      <td>-0.951488</td>\n",
              "      <td>-1.410967</td>\n",
              "      <td>-2.789257</td>\n",
              "      <td>-1.026650</td>\n",
              "      <td>-1.516089</td>\n",
              "      <td>-1.467922</td>\n",
              "      <td>2.695925</td>\n",
              "      <td>2.170062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15037</th>\n",
              "      <td>-1.420423</td>\n",
              "      <td>-0.998236</td>\n",
              "      <td>1.441590</td>\n",
              "      <td>-0.988848</td>\n",
              "      <td>-1.447624</td>\n",
              "      <td>-2.456474</td>\n",
              "      <td>-0.528337</td>\n",
              "      <td>-1.481343</td>\n",
              "      <td>-1.422598</td>\n",
              "      <td>1.924683</td>\n",
              "      <td>2.391165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15038</th>\n",
              "      <td>-1.430734</td>\n",
              "      <td>-0.935839</td>\n",
              "      <td>1.334652</td>\n",
              "      <td>-1.016605</td>\n",
              "      <td>-1.464635</td>\n",
              "      <td>-2.051083</td>\n",
              "      <td>0.057689</td>\n",
              "      <td>-1.428277</td>\n",
              "      <td>-1.377273</td>\n",
              "      <td>1.354150</td>\n",
              "      <td>2.321539</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15039 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df17851e-12a8-4ab1-8079-da117db557d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df17851e-12a8-4ab1-8079-da117db557d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df17851e-12a8-4ab1-8079-da117db557d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting Data"
      ],
      "metadata": {
        "id": "gG17gtLqgKWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=gas_turbstd.drop('TEY',axis=1)\n",
        "y=gas_turbstd['TEY']"
      ],
      "metadata": {
        "id": "xxbms8L2cfVV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
        "x_train.shape, x_test.shape,y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "VCTRr1XQcfYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c08178-3df4-4acf-b6e4-9b89d974a4d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10076, 10), (4963, 10), (10076,), (4963,))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning of Hyperparameters:"
      ],
      "metadata": {
        "id": "-jxnCnYtglC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Batch Size\n",
        "\n",
        "#### Epochs"
      ],
      "metadata": {
        "id": "d9JdYxjKgrIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# libs\n",
        "\n",
        "import tensorflow\n",
        "from sklearn.model_selection import GridSearchCV,KFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "#optimizers\n",
        "from keras.optimizers import adam\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "8SADB1sygi0K"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model def creation\n",
        "def create_model():\n",
        "    model = Sequential(name='Hypterparameter-Tuning-Dummy')\n",
        "    model.add(Dense(12, input_dim=10, kernel_initializer='uniform', activation='relu'))\n",
        "    model.add(Dense(8,kernel_initializer='uniform', activation='relu'))\n",
        "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "    \n",
        "    adam=Adam(learning_rate=0.01)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "s0Dtge2vcfb6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model\n",
        "model=KerasClassifier(build_fn=create_model,verbose=0)\n",
        "#hyper param \n",
        "batch_size=[20,40]\n",
        "epochs=[100,200]\n",
        "# Make a dictionary of the grid search parameters\n",
        "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
        "# Build and fit the GridSearchCV\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(x,y)"
      ],
      "metadata": {
        "id": "z9v5BwqMg4IO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aef5cc19-7d05-4fda-c7d9-fafedd30b807"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV 1/5; 1/4] START batch_size=20, epochs=100...................................\n",
            "[CV 1/5; 1/4] END ....batch_size=20, epochs=100;, score=0.000 total time= 2.4min\n",
            "[CV 2/5; 1/4] START batch_size=20, epochs=100...................................\n",
            "[CV 2/5; 1/4] END ....batch_size=20, epochs=100;, score=0.000 total time= 2.4min\n",
            "[CV 3/5; 1/4] START batch_size=20, epochs=100...................................\n",
            "[CV 3/5; 1/4] END ....batch_size=20, epochs=100;, score=0.000 total time= 2.4min\n",
            "[CV 4/5; 1/4] START batch_size=20, epochs=100...................................\n",
            "[CV 4/5; 1/4] END ....batch_size=20, epochs=100;, score=0.000 total time= 2.4min\n",
            "[CV 5/5; 1/4] START batch_size=20, epochs=100...................................\n",
            "[CV 5/5; 1/4] END ....batch_size=20, epochs=100;, score=0.000 total time= 1.7min\n",
            "[CV 1/5; 2/4] START batch_size=20, epochs=200...................................\n",
            "[CV 1/5; 2/4] END ....batch_size=20, epochs=200;, score=0.000 total time= 3.4min\n",
            "[CV 2/5; 2/4] START batch_size=20, epochs=200...................................\n",
            "[CV 2/5; 2/4] END ....batch_size=20, epochs=200;, score=0.000 total time= 3.2min\n",
            "[CV 3/5; 2/4] START batch_size=20, epochs=200...................................\n",
            "[CV 3/5; 2/4] END ....batch_size=20, epochs=200;, score=0.000 total time= 3.4min\n",
            "[CV 4/5; 2/4] START batch_size=20, epochs=200...................................\n",
            "[CV 4/5; 2/4] END ....batch_size=20, epochs=200;, score=0.000 total time= 3.4min\n",
            "[CV 5/5; 2/4] START batch_size=20, epochs=200...................................\n",
            "[CV 5/5; 2/4] END ....batch_size=20, epochs=200;, score=0.000 total time= 3.4min\n",
            "[CV 1/5; 3/4] START batch_size=40, epochs=100...................................\n",
            "[CV 1/5; 3/4] END ....batch_size=40, epochs=100;, score=0.000 total time=  51.2s\n",
            "[CV 2/5; 3/4] START batch_size=40, epochs=100...................................\n",
            "[CV 2/5; 3/4] END ....batch_size=40, epochs=100;, score=0.000 total time=  53.1s\n",
            "[CV 3/5; 3/4] START batch_size=40, epochs=100...................................\n",
            "[CV 3/5; 3/4] END ....batch_size=40, epochs=100;, score=0.000 total time=  51.9s\n",
            "[CV 4/5; 3/4] START batch_size=40, epochs=100...................................\n",
            "[CV 4/5; 3/4] END ....batch_size=40, epochs=100;, score=0.000 total time=  56.9s\n",
            "[CV 5/5; 3/4] START batch_size=40, epochs=100...................................\n",
            "[CV 5/5; 3/4] END ....batch_size=40, epochs=100;, score=0.000 total time=  52.6s\n",
            "[CV 1/5; 4/4] START batch_size=40, epochs=200...................................\n",
            "[CV 1/5; 4/4] END ....batch_size=40, epochs=200;, score=0.000 total time= 1.8min\n",
            "[CV 2/5; 4/4] START batch_size=40, epochs=200...................................\n",
            "[CV 2/5; 4/4] END ....batch_size=40, epochs=200;, score=0.000 total time= 2.4min\n",
            "[CV 3/5; 4/4] START batch_size=40, epochs=200...................................\n",
            "[CV 3/5; 4/4] END ....batch_size=40, epochs=200;, score=0.000 total time= 2.4min\n",
            "[CV 4/5; 4/4] START batch_size=40, epochs=200...................................\n",
            "[CV 4/5; 4/4] END ....batch_size=40, epochs=200;, score=0.000 total time= 1.7min\n",
            "[CV 5/5; 4/4] START batch_size=40, epochs=200...................................\n",
            "[CV 5/5; 4/4] END ....batch_size=40, epochs=200;, score=0.000 total time= 1.7min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#summarizing results\n",
        "print('Best:{},using{}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means=grid_result.cv_results_['mean_test_score']\n",
        "stds=grid_result.cv_results_['std_test_score']\n",
        "params=grid_result.cv_results_['params']\n",
        "for mean,stdev,param in zip(means,stds,params):\n",
        "  print('{},{} with:{}'.format(mean,stdev,param))"
      ],
      "metadata": {
        "id": "64qxl5oCg4FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd96e44-f42e-4b33-d448-9ff53dbc53df"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best:0.0,using{'batch_size': 20, 'epochs': 100}\n",
            "0.0,0.0 with:{'batch_size': 20, 'epochs': 100}\n",
            "0.0,0.0 with:{'batch_size': 20, 'epochs': 200}\n",
            "0.0,0.0 with:{'batch_size': 40, 'epochs': 100}\n",
            "0.0,0.0 with:{'batch_size': 40, 'epochs': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning of Hyperparameters: Learning rate and Drop out rate"
      ],
      "metadata": {
        "id": "2NqorKmGhFUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dropout\n",
        "\n",
        "#model def\n",
        "def create_model(learning_rate,dropout_rate):\n",
        "  model=Sequential()\n",
        "  model.add(Dense(8,input_dim=10,kernel_initializer='normal',activation='relu'))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "  model.add(Dense(12,input_dim=8,kernel_initializer='normal',activation='relu'))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  adam=Adam(learning_rate=learning_rate)\n",
        "  model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "#model creation\n",
        "model=KerasClassifier(build_fn=create_model,verbose=0,batch_size=40,epochs=50)\n",
        "#grid search params\n",
        "learning_rate=[0.001,0.01,0.1]\n",
        "dropout_rate=[0.0,0.1,0.2]\n",
        "#grid search dictionary\n",
        "param_grids=dict(learning_rate=learning_rate,dropout_rate=dropout_rate)\n",
        "\n",
        "#gridsearch cv fit\n",
        "grid=GridSearchCV(estimator=model,param_grid=param_grids,cv=KFold(),verbose=10)\n",
        "grid_result=grid.fit(x,y)"
      ],
      "metadata": {
        "id": "IJ61ciQ_g4CR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7b0f63-ea01-4f9b-fbe2-59e853eec214"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV 1/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
            "[CV 1/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=  42.3s\n",
            "[CV 2/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
            "[CV 2/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=  25.7s\n",
            "[CV 3/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
            "[CV 3/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=  42.2s\n",
            "[CV 4/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
            "[CV 4/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=  26.0s\n",
            "[CV 5/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
            "[CV 5/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=  42.3s\n",
            "[CV 1/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
            "[CV 1/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=  26.1s\n",
            "[CV 2/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
            "[CV 2/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=  43.0s\n",
            "[CV 3/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
            "[CV 3/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=  26.5s\n",
            "[CV 4/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
            "[CV 4/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=  42.7s\n",
            "[CV 5/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
            "[CV 5/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=  42.3s\n",
            "[CV 1/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
            "[CV 1/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=  26.6s\n",
            "[CV 2/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
            "[CV 2/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=  26.1s\n",
            "[CV 3/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
            "[CV 3/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=  26.2s\n",
            "[CV 4/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
            "[CV 4/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=  42.3s\n",
            "[CV 5/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
            "[CV 5/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=  25.6s\n",
            "[CV 1/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
            "[CV 1/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=  27.1s\n",
            "[CV 2/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
            "[CV 2/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=  42.4s\n",
            "[CV 3/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
            "[CV 3/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=  28.7s\n",
            "[CV 4/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
            "[CV 4/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=  29.2s\n",
            "[CV 5/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
            "[CV 5/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=  42.8s\n",
            "[CV 1/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
            "[CV 1/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=  42.4s\n",
            "[CV 2/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
            "[CV 2/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=  42.4s\n",
            "[CV 3/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
            "[CV 3/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=  28.8s\n",
            "[CV 4/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
            "[CV 4/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=  28.6s\n",
            "[CV 5/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
            "[CV 5/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=  29.0s\n",
            "[CV 1/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
            "[CV 1/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=  27.6s\n",
            "[CV 2/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
            "[CV 2/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=  27.5s\n",
            "[CV 3/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
            "[CV 3/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=  27.2s\n",
            "[CV 4/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
            "[CV 4/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=  42.3s\n",
            "[CV 5/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
            "[CV 5/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=  32.5s\n",
            "[CV 1/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
            "[CV 1/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=  42.6s\n",
            "[CV 2/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
            "[CV 2/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=  29.4s\n",
            "[CV 3/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
            "[CV 3/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=  28.6s\n",
            "[CV 4/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
            "[CV 4/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=  28.9s\n",
            "[CV 5/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
            "[CV 5/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=  28.2s\n",
            "[CV 1/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
            "[CV 1/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=  42.6s\n",
            "[CV 2/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
            "[CV 2/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=  28.6s\n",
            "[CV 3/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
            "[CV 3/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=  27.5s\n",
            "[CV 4/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
            "[CV 4/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=  28.1s\n",
            "[CV 5/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
            "[CV 5/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=  28.1s\n",
            "[CV 1/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
            "[CV 1/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=  42.8s\n",
            "[CV 2/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
            "[CV 2/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=  43.1s\n",
            "[CV 3/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
            "[CV 3/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=  42.9s\n",
            "[CV 4/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
            "[CV 4/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=  42.4s\n",
            "[CV 5/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
            "[CV 5/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=  42.5s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#summarizing results\n",
        "print('Best:{},using{}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means=grid_result.cv_results_['mean_test_score']\n",
        "stds=grid_result.cv_results_['std_test_score']\n",
        "params=grid_result.cv_results_['params']\n",
        "for mean,stdev,param in zip(means,stds,params):\n",
        "  print('{},{} with:{}'.format(mean,stdev,param))"
      ],
      "metadata": {
        "id": "Y19rEywQg3_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f9fe744-7d7e-43a3-fb4f-34537ba4087f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best:0.0,using{'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
            "0.0,0.0 with:{'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
            "0.0,0.0 with:{'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
            "0.0,0.0 with:{'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
            "0.0,0.0 with:{'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
            "0.0,0.0 with:{'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
            "0.0,0.0 with:{'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
            "0.0,0.0 with:{'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "0.0,0.0 with:{'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
            "0.0,0.0 with:{'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning of Hyperparameters:- Activation Function and Kernel Initializer"
      ],
      "metadata": {
        "id": "kdXzpEBIhaxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model def\n",
        "def create_model(activation_function,init):\n",
        "  model=Sequential()\n",
        "  model.add(Dense(8,input_dim=10,kernel_initializer=init,activation=activation_function))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(12,input_dim=8,kernel_initializer=init,activation=activation_function))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  adam=Adam(learning_rate=0.001)\n",
        "  model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "#model creation\n",
        "model=KerasClassifier(build_fn=create_model,verbose=0,batch_size=40,epochs=50)\n",
        "#grid search params\n",
        "activation_function=['softmax','relu','tanh','linear']\n",
        "init=['uniform','normal','zero']\n",
        "#grid search dictionary\n",
        "param_grids=dict(activation_function=activation_function,init=init)\n",
        "\n",
        "#gridsearch cv fit\n",
        "grid=GridSearchCV(estimator=model,param_grid=param_grids,cv=KFold(),verbose=10)\n",
        "grid_result=grid.fit(x,y)"
      ],
      "metadata": {
        "id": "kUyz7CfNg38Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f73abfa-097c-4c80-cc20-d599f99bd9ec"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "[CV 1/5; 1/12] START activation_function=softmax, init=uniform..................\n",
            "[CV 1/5; 1/12] END activation_function=softmax, init=uniform;, score=0.000 total time=  30.5s\n",
            "[CV 2/5; 1/12] START activation_function=softmax, init=uniform..................\n",
            "[CV 2/5; 1/12] END activation_function=softmax, init=uniform;, score=0.000 total time=  42.4s\n",
            "[CV 3/5; 1/12] START activation_function=softmax, init=uniform..................\n",
            "[CV 3/5; 1/12] END activation_function=softmax, init=uniform;, score=0.000 total time=  42.4s\n",
            "[CV 4/5; 1/12] START activation_function=softmax, init=uniform..................\n",
            "[CV 4/5; 1/12] END activation_function=softmax, init=uniform;, score=0.000 total time=  42.7s\n",
            "[CV 5/5; 1/12] START activation_function=softmax, init=uniform..................\n",
            "[CV 5/5; 1/12] END activation_function=softmax, init=uniform;, score=0.000 total time=  42.5s\n",
            "[CV 1/5; 2/12] START activation_function=softmax, init=normal...................\n",
            "[CV 1/5; 2/12] END activation_function=softmax, init=normal;, score=0.000 total time=  27.8s\n",
            "[CV 2/5; 2/12] START activation_function=softmax, init=normal...................\n",
            "[CV 2/5; 2/12] END activation_function=softmax, init=normal;, score=0.000 total time=  42.3s\n",
            "[CV 3/5; 2/12] START activation_function=softmax, init=normal...................\n",
            "[CV 3/5; 2/12] END activation_function=softmax, init=normal;, score=0.000 total time=  43.2s\n",
            "[CV 4/5; 2/12] START activation_function=softmax, init=normal...................\n",
            "[CV 4/5; 2/12] END activation_function=softmax, init=normal;, score=0.000 total time=  30.8s\n",
            "[CV 5/5; 2/12] START activation_function=softmax, init=normal...................\n",
            "[CV 5/5; 2/12] END activation_function=softmax, init=normal;, score=0.000 total time=  29.0s\n",
            "[CV 1/5; 3/12] START activation_function=softmax, init=zero.....................\n",
            "[CV 1/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=  42.6s\n",
            "[CV 2/5; 3/12] START activation_function=softmax, init=zero.....................\n",
            "[CV 2/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=  43.0s\n",
            "[CV 3/5; 3/12] START activation_function=softmax, init=zero.....................\n",
            "[CV 3/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=  42.4s\n",
            "[CV 4/5; 3/12] START activation_function=softmax, init=zero.....................\n",
            "[CV 4/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=  42.9s\n",
            "[CV 5/5; 3/12] START activation_function=softmax, init=zero.....................\n",
            "[CV 5/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=  42.4s\n",
            "[CV 1/5; 4/12] START activation_function=relu, init=uniform.....................\n",
            "[CV 1/5; 4/12] END activation_function=relu, init=uniform;, score=0.000 total time=  29.5s\n",
            "[CV 2/5; 4/12] START activation_function=relu, init=uniform.....................\n",
            "[CV 2/5; 4/12] END activation_function=relu, init=uniform;, score=0.000 total time=  42.3s\n",
            "[CV 3/5; 4/12] START activation_function=relu, init=uniform.....................\n",
            "[CV 3/5; 4/12] END activation_function=relu, init=uniform;, score=0.000 total time=  28.3s\n",
            "[CV 4/5; 4/12] START activation_function=relu, init=uniform.....................\n",
            "[CV 4/5; 4/12] END activation_function=relu, init=uniform;, score=0.000 total time=  29.2s\n",
            "[CV 5/5; 4/12] START activation_function=relu, init=uniform.....................\n",
            "[CV 5/5; 4/12] END activation_function=relu, init=uniform;, score=0.000 total time=  33.6s\n",
            "[CV 1/5; 5/12] START activation_function=relu, init=normal......................\n",
            "[CV 1/5; 5/12] END activation_function=relu, init=normal;, score=0.000 total time=  43.0s\n",
            "[CV 2/5; 5/12] START activation_function=relu, init=normal......................\n",
            "[CV 2/5; 5/12] END activation_function=relu, init=normal;, score=0.000 total time=  42.5s\n",
            "[CV 3/5; 5/12] START activation_function=relu, init=normal......................\n",
            "[CV 3/5; 5/12] END activation_function=relu, init=normal;, score=0.000 total time=  42.7s\n",
            "[CV 4/5; 5/12] START activation_function=relu, init=normal......................\n",
            "[CV 4/5; 5/12] END activation_function=relu, init=normal;, score=0.000 total time=  29.8s\n",
            "[CV 5/5; 5/12] START activation_function=relu, init=normal......................\n",
            "[CV 5/5; 5/12] END activation_function=relu, init=normal;, score=0.000 total time=  42.3s\n",
            "[CV 1/5; 6/12] START activation_function=relu, init=zero........................\n",
            "[CV 1/5; 6/12] END activation_function=relu, init=zero;, score=0.000 total time=  29.5s\n",
            "[CV 2/5; 6/12] START activation_function=relu, init=zero........................\n",
            "[CV 2/5; 6/12] END activation_function=relu, init=zero;, score=0.000 total time=  42.6s\n",
            "[CV 3/5; 6/12] START activation_function=relu, init=zero........................\n",
            "[CV 3/5; 6/12] END activation_function=relu, init=zero;, score=0.000 total time=  29.9s\n",
            "[CV 4/5; 6/12] START activation_function=relu, init=zero........................\n",
            "[CV 4/5; 6/12] END activation_function=relu, init=zero;, score=0.000 total time=  42.5s\n",
            "[CV 5/5; 6/12] START activation_function=relu, init=zero........................\n",
            "[CV 5/5; 6/12] END activation_function=relu, init=zero;, score=0.000 total time=  42.6s\n",
            "[CV 1/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
            "[CV 1/5; 7/12] END activation_function=tanh, init=uniform;, score=0.000 total time=  30.3s\n",
            "[CV 2/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
            "[CV 2/5; 7/12] END activation_function=tanh, init=uniform;, score=0.000 total time=  33.9s\n",
            "[CV 3/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
            "[CV 3/5; 7/12] END activation_function=tanh, init=uniform;, score=0.000 total time=  42.5s\n",
            "[CV 4/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
            "[CV 4/5; 7/12] END activation_function=tanh, init=uniform;, score=0.000 total time=  35.2s\n",
            "[CV 5/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
            "[CV 5/5; 7/12] END activation_function=tanh, init=uniform;, score=0.000 total time=  33.3s\n",
            "[CV 1/5; 8/12] START activation_function=tanh, init=normal......................\n",
            "[CV 1/5; 8/12] END activation_function=tanh, init=normal;, score=0.000 total time=  30.9s\n",
            "[CV 2/5; 8/12] START activation_function=tanh, init=normal......................\n",
            "[CV 2/5; 8/12] END activation_function=tanh, init=normal;, score=0.000 total time=  31.7s\n",
            "[CV 3/5; 8/12] START activation_function=tanh, init=normal......................\n",
            "[CV 3/5; 8/12] END activation_function=tanh, init=normal;, score=0.000 total time=  29.0s\n",
            "[CV 4/5; 8/12] START activation_function=tanh, init=normal......................\n",
            "[CV 4/5; 8/12] END activation_function=tanh, init=normal;, score=0.000 total time=  42.7s\n",
            "[CV 5/5; 8/12] START activation_function=tanh, init=normal......................\n",
            "[CV 5/5; 8/12] END activation_function=tanh, init=normal;, score=0.000 total time=  28.9s\n",
            "[CV 1/5; 9/12] START activation_function=tanh, init=zero........................\n",
            "[CV 1/5; 9/12] END activation_function=tanh, init=zero;, score=0.000 total time=  28.7s\n",
            "[CV 2/5; 9/12] START activation_function=tanh, init=zero........................\n",
            "[CV 2/5; 9/12] END activation_function=tanh, init=zero;, score=0.000 total time=  42.4s\n",
            "[CV 3/5; 9/12] START activation_function=tanh, init=zero........................\n",
            "[CV 3/5; 9/12] END activation_function=tanh, init=zero;, score=0.000 total time=  30.0s\n",
            "[CV 4/5; 9/12] START activation_function=tanh, init=zero........................\n",
            "[CV 4/5; 9/12] END activation_function=tanh, init=zero;, score=0.000 total time=  42.8s\n",
            "[CV 5/5; 9/12] START activation_function=tanh, init=zero........................\n",
            "[CV 5/5; 9/12] END activation_function=tanh, init=zero;, score=0.000 total time=  42.6s\n",
            "[CV 1/5; 10/12] START activation_function=linear, init=uniform..................\n",
            "[CV 1/5; 10/12] END activation_function=linear, init=uniform;, score=0.000 total time=  42.8s\n",
            "[CV 2/5; 10/12] START activation_function=linear, init=uniform..................\n",
            "[CV 2/5; 10/12] END activation_function=linear, init=uniform;, score=0.000 total time=  30.7s\n",
            "[CV 3/5; 10/12] START activation_function=linear, init=uniform..................\n",
            "[CV 3/5; 10/12] END activation_function=linear, init=uniform;, score=0.000 total time=  29.7s\n",
            "[CV 4/5; 10/12] START activation_function=linear, init=uniform..................\n",
            "[CV 4/5; 10/12] END activation_function=linear, init=uniform;, score=0.000 total time=  42.4s\n",
            "[CV 5/5; 10/12] START activation_function=linear, init=uniform..................\n",
            "[CV 5/5; 10/12] END activation_function=linear, init=uniform;, score=0.002 total time=  27.7s\n",
            "[CV 1/5; 11/12] START activation_function=linear, init=normal...................\n",
            "[CV 1/5; 11/12] END activation_function=linear, init=normal;, score=0.000 total time=  42.4s\n",
            "[CV 2/5; 11/12] START activation_function=linear, init=normal...................\n",
            "[CV 2/5; 11/12] END activation_function=linear, init=normal;, score=0.000 total time=  28.2s\n",
            "[CV 3/5; 11/12] START activation_function=linear, init=normal...................\n",
            "[CV 3/5; 11/12] END activation_function=linear, init=normal;, score=0.000 total time=  42.4s\n",
            "[CV 4/5; 11/12] START activation_function=linear, init=normal...................\n",
            "[CV 4/5; 11/12] END activation_function=linear, init=normal;, score=0.000 total time=  42.7s\n",
            "[CV 5/5; 11/12] START activation_function=linear, init=normal...................\n",
            "[CV 5/5; 11/12] END activation_function=linear, init=normal;, score=0.002 total time=  30.0s\n",
            "[CV 1/5; 12/12] START activation_function=linear, init=zero.....................\n",
            "[CV 1/5; 12/12] END activation_function=linear, init=zero;, score=0.000 total time=  43.7s\n",
            "[CV 2/5; 12/12] START activation_function=linear, init=zero.....................\n",
            "[CV 2/5; 12/12] END activation_function=linear, init=zero;, score=0.000 total time=  32.1s\n",
            "[CV 3/5; 12/12] START activation_function=linear, init=zero.....................\n",
            "[CV 3/5; 12/12] END activation_function=linear, init=zero;, score=0.000 total time=  33.3s\n",
            "[CV 4/5; 12/12] START activation_function=linear, init=zero.....................\n",
            "[CV 4/5; 12/12] END activation_function=linear, init=zero;, score=0.000 total time=  42.5s\n",
            "[CV 5/5; 12/12] START activation_function=linear, init=zero.....................\n",
            "[CV 5/5; 12/12] END activation_function=linear, init=zero;, score=0.000 total time=  34.8s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarizin results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "metadata": {
        "id": "YmCR3Ruug33l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14adf457-249e-48ce-b648-cf770bf08a24"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best : 0.00033255736343562603, using {'activation_function': 'linear', 'init': 'uniform'}\n",
            "0.0,0.0 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
            "0.0,0.0 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
            "0.0,0.0 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
            "0.0,0.0 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
            "0.0,0.0 with: {'activation_function': 'relu', 'init': 'normal'}\n",
            "0.0,0.0 with: {'activation_function': 'relu', 'init': 'zero'}\n",
            "0.0,0.0 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
            "0.0,0.0 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
            "0.0,0.0 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
            "0.00033255736343562603,0.0006651147268712521 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
            "0.00033255736343562603,0.0006651147268712521 with: {'activation_function': 'linear', 'init': 'normal'}\n",
            "0.0,0.0 with: {'activation_function': 'linear', 'init': 'zero'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training model with optimum values of Hyperparameters"
      ],
      "metadata": {
        "id": "INTe0inghtow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python program to define a function to compute accuracy score of model's predicted class  \n",
        "  \n",
        "# Defining a function which takes true values of the sample and values predicted by the model  \n",
        "def compute_accuracy(Y_true, Y_pred):  \n",
        "    correctly_predicted = 0  \n",
        "    # iterating over every label and checking it with the true sample  \n",
        "    for true_label, predicted in zip(Y_true, Y_pred):  \n",
        "        if true_label == predicted:  \n",
        "            correctly_predicted += 1  \n",
        "    # computing the accuracy score  \n",
        "    accuracy_score = correctly_predicted / len(Y_true)  \n",
        "    return accuracy_score  "
      ],
      "metadata": {
        "id": "84UDYo9ehlNZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "#model def\n",
        "def create_model():\n",
        "  model=Sequential()\n",
        "  model.add(Dense(16,input_dim=10,kernel_initializer='uniform',activation='tanh'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(4,input_dim=16,kernel_initializer='uniform',activation='tanh'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  adam=Adam(learning_rate=0.1)\n",
        "  model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "#model creation\n",
        "model=KerasClassifier(build_fn=create_model,verbose=0,batch_size=5000,epochs=100)\n",
        "#model fit\n",
        "model.fit(x,y)\n",
        "#prediction on train \n",
        "y_pred=model.predict(x)\n",
        "#printing mertics\n",
        "compute_accuracy(y,y_pred)"
      ],
      "metadata": {
        "id": "XNil-ZtHhlC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6626772-5c94-4aaf-a979-0a7fc1844998"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "470/470 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.649378283130527e-05"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forBestParams(x_train, y_train, x_test, y_test):\n",
        "\n",
        "    # Defining list of hyperparameters\n",
        "    batch_size_list = [500 , 1000 , 1500 , 2000 ]\n",
        "    epoch_list      = [50 , 100 , 150 , 200]\n",
        "           \n",
        "    # Initializing the trials\n",
        "    for batch_trial in batch_size_list:\n",
        "        for epochs_trial in epoch_list:\n",
        "            \n",
        "            # Create ANN model\n",
        "            model = Sequential()\n",
        "            \n",
        "            # Defining the first layer of the model\n",
        "            model.add(Dense(units=50, input_dim=x_train.shape[1], kernel_initializer='normal', activation='tanh'))\n",
        "            \n",
        "            # Defining the Second layer of the model\n",
        "            model.add(Dense(units=6, kernel_initializer='normal', activation='tanh'))\n",
        " \n",
        "            # The output neuron is a single fully connected node Since we will be predicting a single number\n",
        "            model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        " \n",
        "            # Compiling the model\n",
        "            model.compile(loss='binary_crossentropy', optimizer='adam',  metrics=['accuracy'])\n",
        " \n",
        "            # Fitting the ANN to the Training set\n",
        "            model_trained = model.fit(x_train, y_train ,batch_size = batch_trial, epochs = epochs_trial, verbose=0)\n",
        "               \n",
        "            # Fetching the accuracy of the training\n",
        "            Accuracy_train = model_trained.history['accuracy'][-1]   \n",
        "            \n",
        "            # Printing the results of the current iteration\n",
        "            print('batch_size:', batch_trial,'-', 'epochs:',epochs_trial, 'Accuracy:',Accuracy_train)\n",
        "\n",
        "# Calling the function\n",
        "forBestParams(x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "id": "kEECZ7SDhk7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d35217e6-b8a0-4e33-8ee3-4498fdd4fda3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size: 500 - epochs: 50 Accuracy: 0.0\n",
            "batch_size: 500 - epochs: 100 Accuracy: 0.0\n",
            "batch_size: 500 - epochs: 150 Accuracy: 0.0\n",
            "batch_size: 500 - epochs: 200 Accuracy: 0.0\n",
            "batch_size: 1000 - epochs: 50 Accuracy: 0.0\n",
            "batch_size: 1000 - epochs: 100 Accuracy: 0.0\n",
            "batch_size: 1000 - epochs: 150 Accuracy: 0.0\n",
            "batch_size: 1000 - epochs: 200 Accuracy: 0.0\n",
            "batch_size: 1500 - epochs: 50 Accuracy: 0.0\n",
            "batch_size: 1500 - epochs: 100 Accuracy: 0.0\n",
            "batch_size: 1500 - epochs: 150 Accuracy: 0.0\n",
            "batch_size: 1500 - epochs: 200 Accuracy: 0.0\n",
            "batch_size: 2000 - epochs: 50 Accuracy: 0.0\n",
            "batch_size: 2000 - epochs: 100 Accuracy: 0.0\n",
            "batch_size: 2000 - epochs: 150 Accuracy: 0.0\n",
            "batch_size: 2000 - epochs: 200 Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Regressor"
      ],
      "metadata": {
        "id": "sp5Q6EcmiD-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(30,30))\n",
        "mlp.fit(x_train,y_train)\n",
        "pred_train=mlp.predict(x_train)\n",
        "pred_test=mlp.predict(x_test)"
      ],
      "metadata": {
        "id": "QAzyEAwFhkwI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "rs1=r2_score(y_train,pred_train)\n",
        "mse1=mean_squared_error(y_train,pred_train)\n",
        "rs1,mse1"
      ],
      "metadata": {
        "id": "4cLACvRug3wq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3878d03a-fe0c-4da2-f6e0-392f2ff45fb0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9978801188740483, 0.0021161693531286494)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rs2=r2_score(y_test,pred_test)\n",
        "mse2=mean_squared_error(y_train,pred_train)\n",
        "rs2,mse2"
      ],
      "metadata": {
        "id": "ktH1PlmdiMr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcdd6d56-ac64-47f2-97a7-e6e6bfdc750f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.997774074896175, 0.0021161693531286494)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras \n",
        "!pip install tensorflow\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "vm2NbDVeiMnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac8bfbd8-33c1-47da-d948-f22a5869c6ce"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.8)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(15,input_dim=10,activation=\"relu\"))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"mean_squared_error\"])"
      ],
      "metadata": {
        "id": "Y2GMbRLYiMhG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(x,y,validation_split=0.33,epochs=250,batch_size=10)\n",
        "scores=model.evaluate(x,y)\n",
        "print(\"%s: %.2f%%\"%(model.metrics_names[1],scores[1]*100))\n",
        "history.history.keys()"
      ],
      "metadata": {
        "id": "PLrk65imiMbJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe786b38-0b69-4b1c-edf1-3252c28c151c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -1322809.5000 - mean_squared_error: 0.5791 - val_loss: -1495410.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 2/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1333214.0000 - mean_squared_error: 0.5792 - val_loss: -1507171.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 3/250\n",
            "1008/1008 [==============================] - 6s 6ms/step - loss: -1343672.8750 - mean_squared_error: 0.5791 - val_loss: -1518925.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 4/250\n",
            "1008/1008 [==============================] - 8s 8ms/step - loss: -1354134.2500 - mean_squared_error: 0.5792 - val_loss: -1530699.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 5/250\n",
            "1008/1008 [==============================] - 7s 7ms/step - loss: -1364650.8750 - mean_squared_error: 0.5791 - val_loss: -1542620.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 6/250\n",
            "1008/1008 [==============================] - 7s 7ms/step - loss: -1375200.7500 - mean_squared_error: 0.5792 - val_loss: -1554516.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 7/250\n",
            "1008/1008 [==============================] - 10s 10ms/step - loss: -1385801.2500 - mean_squared_error: 0.5792 - val_loss: -1566472.3750 - val_mean_squared_error: 0.6451\n",
            "Epoch 8/250\n",
            "1008/1008 [==============================] - 7s 7ms/step - loss: -1396453.8750 - mean_squared_error: 0.5792 - val_loss: -1578516.8750 - val_mean_squared_error: 0.6451\n",
            "Epoch 9/250\n",
            "1008/1008 [==============================] - 8s 8ms/step - loss: -1407177.3750 - mean_squared_error: 0.5792 - val_loss: -1590607.8750 - val_mean_squared_error: 0.6451\n",
            "Epoch 10/250\n",
            "1008/1008 [==============================] - 7s 7ms/step - loss: -1417900.6250 - mean_squared_error: 0.5792 - val_loss: -1602678.1250 - val_mean_squared_error: 0.6451\n",
            "Epoch 11/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -1428624.2500 - mean_squared_error: 0.5792 - val_loss: -1614809.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 12/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1439467.1250 - mean_squared_error: 0.5792 - val_loss: -1627030.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 13/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -1450349.6250 - mean_squared_error: 0.5792 - val_loss: -1639358.8750 - val_mean_squared_error: 0.6451\n",
            "Epoch 14/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1461246.0000 - mean_squared_error: 0.5792 - val_loss: -1651553.3750 - val_mean_squared_error: 0.6451\n",
            "Epoch 15/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1472155.2500 - mean_squared_error: 0.5792 - val_loss: -1663868.3750 - val_mean_squared_error: 0.6451\n",
            "Epoch 16/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1483130.1250 - mean_squared_error: 0.5792 - val_loss: -1676291.8750 - val_mean_squared_error: 0.6451\n",
            "Epoch 17/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1494136.8750 - mean_squared_error: 0.5792 - val_loss: -1688705.6250 - val_mean_squared_error: 0.6451\n",
            "Epoch 18/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -1505180.0000 - mean_squared_error: 0.5792 - val_loss: -1701176.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 19/250\n",
            "1008/1008 [==============================] - 4s 3ms/step - loss: -1516216.0000 - mean_squared_error: 0.5792 - val_loss: -1713530.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 20/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1527287.3750 - mean_squared_error: 0.5792 - val_loss: -1725998.6250 - val_mean_squared_error: 0.6451\n",
            "Epoch 21/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -1538405.8750 - mean_squared_error: 0.5792 - val_loss: -1738581.6250 - val_mean_squared_error: 0.6451\n",
            "Epoch 22/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -1549625.5000 - mean_squared_error: 0.5792 - val_loss: -1751203.8750 - val_mean_squared_error: 0.6451\n",
            "Epoch 23/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1560857.0000 - mean_squared_error: 0.5792 - val_loss: -1763850.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 24/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1572053.3750 - mean_squared_error: 0.5792 - val_loss: -1776474.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 25/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1583265.6250 - mean_squared_error: 0.5792 - val_loss: -1789055.1250 - val_mean_squared_error: 0.6451\n",
            "Epoch 26/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1594567.8750 - mean_squared_error: 0.5792 - val_loss: -1801856.8750 - val_mean_squared_error: 0.6451\n",
            "Epoch 27/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1606008.1250 - mean_squared_error: 0.5793 - val_loss: -1814811.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 28/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1617473.6250 - mean_squared_error: 0.5793 - val_loss: -1827712.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 29/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1628954.2500 - mean_squared_error: 0.5793 - val_loss: -1840701.3750 - val_mean_squared_error: 0.6451\n",
            "Epoch 30/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -1640504.3750 - mean_squared_error: 0.5793 - val_loss: -1853686.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 31/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1652035.5000 - mean_squared_error: 0.5793 - val_loss: -1866686.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 32/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1663672.5000 - mean_squared_error: 0.5792 - val_loss: -1879865.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 33/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1675326.6250 - mean_squared_error: 0.5792 - val_loss: -1892932.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 34/250\n",
            "1008/1008 [==============================] - 5s 5ms/step - loss: -1686952.3750 - mean_squared_error: 0.5793 - val_loss: -1906060.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 35/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1698703.1250 - mean_squared_error: 0.5792 - val_loss: -1919368.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 36/250\n",
            "1008/1008 [==============================] - 4s 3ms/step - loss: -1710494.0000 - mean_squared_error: 0.5792 - val_loss: -1932584.8750 - val_mean_squared_error: 0.6451\n",
            "Epoch 37/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -1722249.7500 - mean_squared_error: 0.5793 - val_loss: -1945854.6250 - val_mean_squared_error: 0.6451\n",
            "Epoch 38/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1734117.6250 - mean_squared_error: 0.5792 - val_loss: -1959321.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 39/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1746046.0000 - mean_squared_error: 0.5792 - val_loss: -1972735.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 40/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -1757971.0000 - mean_squared_error: 0.5793 - val_loss: -1986151.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 41/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -1769973.0000 - mean_squared_error: 0.5792 - val_loss: -1999724.8750 - val_mean_squared_error: 0.6451\n",
            "Epoch 42/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1782061.6250 - mean_squared_error: 0.5793 - val_loss: -2013374.8750 - val_mean_squared_error: 0.6451\n",
            "Epoch 43/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1794214.2500 - mean_squared_error: 0.5792 - val_loss: -2027126.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 44/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -1806371.1250 - mean_squared_error: 0.5792 - val_loss: -2040762.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 45/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -1818537.3750 - mean_squared_error: 0.5792 - val_loss: -2054541.6250 - val_mean_squared_error: 0.6451\n",
            "Epoch 46/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1830772.1250 - mean_squared_error: 0.5791 - val_loss: -2068309.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 47/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1842950.0000 - mean_squared_error: 0.5792 - val_loss: -2082029.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 48/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1855147.7500 - mean_squared_error: 0.5792 - val_loss: -2095835.6250 - val_mean_squared_error: 0.6451\n",
            "Epoch 49/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -1867420.2500 - mean_squared_error: 0.5791 - val_loss: -2109662.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 50/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1879773.5000 - mean_squared_error: 0.5792 - val_loss: -2123624.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 51/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1892113.6250 - mean_squared_error: 0.5791 - val_loss: -2137480.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 52/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1904478.8750 - mean_squared_error: 0.5792 - val_loss: -2151468.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 53/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -1916886.7500 - mean_squared_error: 0.5792 - val_loss: -2165386.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 54/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1929349.1250 - mean_squared_error: 0.5792 - val_loss: -2179530.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 55/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1941865.6250 - mean_squared_error: 0.5792 - val_loss: -2193583.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 56/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -1954376.5000 - mean_squared_error: 0.5792 - val_loss: -2207609.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 57/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -1966906.3750 - mean_squared_error: 0.5792 - val_loss: -2221725.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 58/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1979466.7500 - mean_squared_error: 0.5791 - val_loss: -2235874.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 59/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -1992144.0000 - mean_squared_error: 0.5793 - val_loss: -2250198.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 60/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2004869.3750 - mean_squared_error: 0.5793 - val_loss: -2264574.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 61/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2017664.0000 - mean_squared_error: 0.5792 - val_loss: -2278992.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 62/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2030538.7500 - mean_squared_error: 0.5793 - val_loss: -2293518.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 63/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2043351.5000 - mean_squared_error: 0.5793 - val_loss: -2307909.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 64/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2056208.5000 - mean_squared_error: 0.5793 - val_loss: -2322433.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 65/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2069155.6250 - mean_squared_error: 0.5793 - val_loss: -2337072.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 66/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2082164.0000 - mean_squared_error: 0.5793 - val_loss: -2351812.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 67/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2095240.7500 - mean_squared_error: 0.5793 - val_loss: -2366518.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 68/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2108380.0000 - mean_squared_error: 0.5793 - val_loss: -2381365.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 69/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2121540.2500 - mean_squared_error: 0.5793 - val_loss: -2396232.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 70/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2134763.2500 - mean_squared_error: 0.5792 - val_loss: -2411228.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 71/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2148146.0000 - mean_squared_error: 0.5792 - val_loss: -2426366.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 72/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2161470.7500 - mean_squared_error: 0.5792 - val_loss: -2441263.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 73/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2174764.5000 - mean_squared_error: 0.5792 - val_loss: -2456288.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 74/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2188101.5000 - mean_squared_error: 0.5793 - val_loss: -2471268.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 75/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2201431.7500 - mean_squared_error: 0.5793 - val_loss: -2486308.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 76/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2214859.2500 - mean_squared_error: 0.5793 - val_loss: -2501418.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 77/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2228308.2500 - mean_squared_error: 0.5793 - val_loss: -2516527.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 78/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2241740.7500 - mean_squared_error: 0.5792 - val_loss: -2531671.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 79/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2255280.7500 - mean_squared_error: 0.5793 - val_loss: -2547017.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 80/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2268848.2500 - mean_squared_error: 0.5792 - val_loss: -2562237.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 81/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2282432.2500 - mean_squared_error: 0.5792 - val_loss: -2577583.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 82/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2296038.7500 - mean_squared_error: 0.5792 - val_loss: -2592868.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 83/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2309646.5000 - mean_squared_error: 0.5793 - val_loss: -2608246.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 84/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2323299.7500 - mean_squared_error: 0.5793 - val_loss: -2623576.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 85/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2336937.5000 - mean_squared_error: 0.5793 - val_loss: -2639017.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 86/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2350642.7500 - mean_squared_error: 0.5793 - val_loss: -2654395.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 87/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2364446.5000 - mean_squared_error: 0.5793 - val_loss: -2669971.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 88/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2378334.2500 - mean_squared_error: 0.5793 - val_loss: -2685673.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 89/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2392268.5000 - mean_squared_error: 0.5793 - val_loss: -2701364.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 90/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2406251.7500 - mean_squared_error: 0.5793 - val_loss: -2717109.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 91/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2420237.0000 - mean_squared_error: 0.5793 - val_loss: -2732869.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 92/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2434271.0000 - mean_squared_error: 0.5793 - val_loss: -2748660.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 93/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2448362.7500 - mean_squared_error: 0.5793 - val_loss: -2764573.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 94/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2462490.5000 - mean_squared_error: 0.5793 - val_loss: -2780496.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 95/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2476695.7500 - mean_squared_error: 0.5793 - val_loss: -2796486.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 96/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2490870.2500 - mean_squared_error: 0.5793 - val_loss: -2812445.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 97/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2505069.7500 - mean_squared_error: 0.5793 - val_loss: -2828391.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 98/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2519277.2500 - mean_squared_error: 0.5793 - val_loss: -2844493.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 99/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2533579.5000 - mean_squared_error: 0.5793 - val_loss: -2860550.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 100/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2547917.7500 - mean_squared_error: 0.5793 - val_loss: -2876720.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 101/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2562268.5000 - mean_squared_error: 0.5793 - val_loss: -2892834.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 102/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2576684.5000 - mean_squared_error: 0.5793 - val_loss: -2909123.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 103/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2591150.0000 - mean_squared_error: 0.5793 - val_loss: -2925418.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 104/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2605647.5000 - mean_squared_error: 0.5793 - val_loss: -2941775.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 105/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2620212.0000 - mean_squared_error: 0.5793 - val_loss: -2958205.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 106/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2634881.0000 - mean_squared_error: 0.5793 - val_loss: -2974735.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 107/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2649503.0000 - mean_squared_error: 0.5792 - val_loss: -2991128.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 108/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2664217.7500 - mean_squared_error: 0.5793 - val_loss: -3007759.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 109/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2678921.2500 - mean_squared_error: 0.5793 - val_loss: -3024192.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 110/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2693673.7500 - mean_squared_error: 0.5793 - val_loss: -3040814.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 111/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2708456.5000 - mean_squared_error: 0.5793 - val_loss: -3057461.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 112/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2723295.0000 - mean_squared_error: 0.5792 - val_loss: -3074246.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 113/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2738230.0000 - mean_squared_error: 0.5793 - val_loss: -3091121.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 114/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2753171.2500 - mean_squared_error: 0.5792 - val_loss: -3107904.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 115/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2768110.5000 - mean_squared_error: 0.5793 - val_loss: -3124773.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 116/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2783135.0000 - mean_squared_error: 0.5793 - val_loss: -3141712.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 117/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2798215.2500 - mean_squared_error: 0.5793 - val_loss: -3158726.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 118/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2813304.7500 - mean_squared_error: 0.5793 - val_loss: -3175728.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 119/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2828424.0000 - mean_squared_error: 0.5792 - val_loss: -3192777.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 120/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2843613.7500 - mean_squared_error: 0.5792 - val_loss: -3209931.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 121/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2858882.0000 - mean_squared_error: 0.5792 - val_loss: -3227177.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 122/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2874200.0000 - mean_squared_error: 0.5793 - val_loss: -3244475.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 123/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2889507.7500 - mean_squared_error: 0.5792 - val_loss: -3261695.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 124/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2904924.0000 - mean_squared_error: 0.5793 - val_loss: -3279128.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 125/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2920388.2500 - mean_squared_error: 0.5793 - val_loss: -3296482.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 126/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2935785.0000 - mean_squared_error: 0.5793 - val_loss: -3313845.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 127/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2951240.2500 - mean_squared_error: 0.5793 - val_loss: -3331320.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 128/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -2966734.5000 - mean_squared_error: 0.5793 - val_loss: -3348783.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 129/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2982264.7500 - mean_squared_error: 0.5793 - val_loss: -3366255.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 130/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -2997853.5000 - mean_squared_error: 0.5793 - val_loss: -3383767.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 131/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3013403.5000 - mean_squared_error: 0.5793 - val_loss: -3401328.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 132/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3029001.2500 - mean_squared_error: 0.5793 - val_loss: -3418856.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 133/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3044731.2500 - mean_squared_error: 0.5793 - val_loss: -3436597.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 134/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3060506.2500 - mean_squared_error: 0.5793 - val_loss: -3454404.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 135/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3076257.5000 - mean_squared_error: 0.5793 - val_loss: -3472173.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 136/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -3092110.2500 - mean_squared_error: 0.5793 - val_loss: -3490059.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 137/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3107846.0000 - mean_squared_error: 0.5792 - val_loss: -3507745.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 138/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3123613.0000 - mean_squared_error: 0.5793 - val_loss: -3525546.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 139/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3139543.2500 - mean_squared_error: 0.5793 - val_loss: -3543524.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 140/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -3155542.7500 - mean_squared_error: 0.5793 - val_loss: -3561615.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 141/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3171554.5000 - mean_squared_error: 0.5793 - val_loss: -3579651.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 142/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3187666.0000 - mean_squared_error: 0.5793 - val_loss: -3597847.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 143/250\n",
            "1008/1008 [==============================] - 4s 3ms/step - loss: -3203799.7500 - mean_squared_error: 0.5793 - val_loss: -3615956.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 144/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -3219972.0000 - mean_squared_error: 0.5793 - val_loss: -3634174.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 145/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3236127.0000 - mean_squared_error: 0.5793 - val_loss: -3652325.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 146/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3252272.2500 - mean_squared_error: 0.5793 - val_loss: -3670502.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 147/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3268527.0000 - mean_squared_error: 0.5792 - val_loss: -3688852.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 148/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -3284854.0000 - mean_squared_error: 0.5793 - val_loss: -3707260.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 149/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3301195.5000 - mean_squared_error: 0.5793 - val_loss: -3725704.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 150/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3317549.7500 - mean_squared_error: 0.5793 - val_loss: -3744101.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 151/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3333923.7500 - mean_squared_error: 0.5793 - val_loss: -3762601.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 152/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3350402.5000 - mean_squared_error: 0.5793 - val_loss: -3781126.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 153/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3366897.7500 - mean_squared_error: 0.5793 - val_loss: -3799690.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 154/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3383493.0000 - mean_squared_error: 0.5793 - val_loss: -3818448.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 155/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -3400119.7500 - mean_squared_error: 0.5793 - val_loss: -3837190.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 156/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3416766.0000 - mean_squared_error: 0.5793 - val_loss: -3856030.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 157/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3433435.7500 - mean_squared_error: 0.5793 - val_loss: -3874728.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 158/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3450163.7500 - mean_squared_error: 0.5792 - val_loss: -3893690.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 159/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -3466950.5000 - mean_squared_error: 0.5793 - val_loss: -3912632.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 160/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3483688.7500 - mean_squared_error: 0.5793 - val_loss: -3931407.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 161/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3500480.7500 - mean_squared_error: 0.5792 - val_loss: -3950490.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 162/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -3517340.7500 - mean_squared_error: 0.5793 - val_loss: -3969431.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 163/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3534211.5000 - mean_squared_error: 0.5793 - val_loss: -3988439.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 164/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -3551080.7500 - mean_squared_error: 0.5792 - val_loss: -4007398.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 165/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3567973.7500 - mean_squared_error: 0.5793 - val_loss: -4026532.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 166/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -3585026.7500 - mean_squared_error: 0.5793 - val_loss: -4045794.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 167/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3602198.2500 - mean_squared_error: 0.5793 - val_loss: -4065149.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 168/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3619368.5000 - mean_squared_error: 0.5793 - val_loss: -4084495.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 169/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3636504.5000 - mean_squared_error: 0.5793 - val_loss: -4103774.7500 - val_mean_squared_error: 0.6451\n",
            "Epoch 170/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -3653701.0000 - mean_squared_error: 0.5793 - val_loss: -4123192.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 171/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3670965.2500 - mean_squared_error: 0.5793 - val_loss: -4142665.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 172/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3688244.0000 - mean_squared_error: 0.5793 - val_loss: -4162107.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 173/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3705539.2500 - mean_squared_error: 0.5793 - val_loss: -4181557.2500 - val_mean_squared_error: 0.6451\n",
            "Epoch 174/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -3722821.7500 - mean_squared_error: 0.5793 - val_loss: -4201016.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 175/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3740146.0000 - mean_squared_error: 0.5793 - val_loss: -4220542.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 176/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3757546.2500 - mean_squared_error: 0.5793 - val_loss: -4240313.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 177/250\n",
            "1008/1008 [==============================] - 4s 3ms/step - loss: -3774995.0000 - mean_squared_error: 0.5793 - val_loss: -4259909.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 178/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -3792523.2500 - mean_squared_error: 0.5793 - val_loss: -4279769.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 179/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3810084.0000 - mean_squared_error: 0.5793 - val_loss: -4299560.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 180/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3827640.0000 - mean_squared_error: 0.5793 - val_loss: -4319290.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 181/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -3845246.5000 - mean_squared_error: 0.5793 - val_loss: -4339196.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 182/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3862837.0000 - mean_squared_error: 0.5793 - val_loss: -4359012.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 183/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3880562.0000 - mean_squared_error: 0.5793 - val_loss: -4379073.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 184/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3898341.5000 - mean_squared_error: 0.5793 - val_loss: -4398993.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 185/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -3916064.2500 - mean_squared_error: 0.5793 - val_loss: -4419018.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 186/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3933836.5000 - mean_squared_error: 0.5793 - val_loss: -4439053.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 187/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3951640.7500 - mean_squared_error: 0.5793 - val_loss: -4459170.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 188/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -3969520.0000 - mean_squared_error: 0.5793 - val_loss: -4479408.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 189/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -3987540.2500 - mean_squared_error: 0.5793 - val_loss: -4499660.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 190/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4005555.5000 - mean_squared_error: 0.5793 - val_loss: -4519961.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 191/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4023577.2500 - mean_squared_error: 0.5793 - val_loss: -4540120.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 192/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4041525.5000 - mean_squared_error: 0.5793 - val_loss: -4560349.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 193/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -4059493.2500 - mean_squared_error: 0.5793 - val_loss: -4580674.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 194/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4077711.0000 - mean_squared_error: 0.5793 - val_loss: -4601270.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 195/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4095942.7500 - mean_squared_error: 0.5793 - val_loss: -4621754.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 196/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4114114.0000 - mean_squared_error: 0.5793 - val_loss: -4642326.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 197/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4132344.5000 - mean_squared_error: 0.5793 - val_loss: -4662899.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 198/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4150676.5000 - mean_squared_error: 0.5793 - val_loss: -4683494.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 199/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4169048.2500 - mean_squared_error: 0.5793 - val_loss: -4704204.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 200/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4187378.2500 - mean_squared_error: 0.5793 - val_loss: -4724827.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 201/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -4205748.5000 - mean_squared_error: 0.5793 - val_loss: -4745496.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 202/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4224164.0000 - mean_squared_error: 0.5793 - val_loss: -4766304.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 203/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4242678.0000 - mean_squared_error: 0.5793 - val_loss: -4787063.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 204/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4261202.0000 - mean_squared_error: 0.5793 - val_loss: -4808104.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 205/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4279893.5000 - mean_squared_error: 0.5793 - val_loss: -4829198.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 206/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4298602.0000 - mean_squared_error: 0.5793 - val_loss: -4850267.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 207/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -4317359.0000 - mean_squared_error: 0.5793 - val_loss: -4871428.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 208/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4336110.5000 - mean_squared_error: 0.5793 - val_loss: -4892508.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 209/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4354916.5000 - mean_squared_error: 0.5793 - val_loss: -4913798.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 210/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4373751.5000 - mean_squared_error: 0.5793 - val_loss: -4935010.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 211/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4392706.5000 - mean_squared_error: 0.5793 - val_loss: -4956444.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 212/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4411704.0000 - mean_squared_error: 0.5793 - val_loss: -4977750.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 213/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4430588.0000 - mean_squared_error: 0.5793 - val_loss: -4998939.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 214/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4449480.5000 - mean_squared_error: 0.5793 - val_loss: -5020399.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 215/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4468540.5000 - mean_squared_error: 0.5793 - val_loss: -5041881.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 216/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -4487672.5000 - mean_squared_error: 0.5793 - val_loss: -5063470.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 217/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4506772.0000 - mean_squared_error: 0.5793 - val_loss: -5084946.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 218/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4525917.5000 - mean_squared_error: 0.5793 - val_loss: -5106527.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 219/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4545093.5000 - mean_squared_error: 0.5793 - val_loss: -5128072.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 220/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -4564375.0000 - mean_squared_error: 0.5793 - val_loss: -5149913.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 221/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4583710.0000 - mean_squared_error: 0.5793 - val_loss: -5171643.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 222/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4602905.5000 - mean_squared_error: 0.5793 - val_loss: -5193228.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 223/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4622230.0000 - mean_squared_error: 0.5793 - val_loss: -5215079.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 224/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -4641722.0000 - mean_squared_error: 0.5793 - val_loss: -5237096.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 225/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -4661242.5000 - mean_squared_error: 0.5793 - val_loss: -5259021.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 226/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -4680777.0000 - mean_squared_error: 0.5793 - val_loss: -5281077.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 227/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -4700358.5000 - mean_squared_error: 0.5793 - val_loss: -5303157.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 228/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4719892.5000 - mean_squared_error: 0.5793 - val_loss: -5325001.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 229/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -4739370.5000 - mean_squared_error: 0.5793 - val_loss: -5347020.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 230/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4758973.0000 - mean_squared_error: 0.5793 - val_loss: -5369070.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 231/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -4778702.5000 - mean_squared_error: 0.5793 - val_loss: -5391438.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 232/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4798444.0000 - mean_squared_error: 0.5793 - val_loss: -5413512.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 233/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4818071.5000 - mean_squared_error: 0.5793 - val_loss: -5435605.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 234/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -4837868.5000 - mean_squared_error: 0.5793 - val_loss: -5457982.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 235/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4857724.0000 - mean_squared_error: 0.5793 - val_loss: -5480372.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 236/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -4877663.0000 - mean_squared_error: 0.5793 - val_loss: -5502789.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 237/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -4897573.0000 - mean_squared_error: 0.5792 - val_loss: -5525183.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 238/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4917431.0000 - mean_squared_error: 0.5793 - val_loss: -5547580.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 239/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -4937390.5000 - mean_squared_error: 0.5793 - val_loss: -5570047.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 240/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -4957470.0000 - mean_squared_error: 0.5792 - val_loss: -5592701.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 241/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4977506.5000 - mean_squared_error: 0.5793 - val_loss: -5615260.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 242/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -4997542.5000 - mean_squared_error: 0.5793 - val_loss: -5637949.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 243/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -5017760.5000 - mean_squared_error: 0.5793 - val_loss: -5660819.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 244/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -5038087.5000 - mean_squared_error: 0.5793 - val_loss: -5683723.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 245/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -5058426.5000 - mean_squared_error: 0.5792 - val_loss: -5706689.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 246/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -5078699.0000 - mean_squared_error: 0.5792 - val_loss: -5729494.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 247/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -5099013.0000 - mean_squared_error: 0.5793 - val_loss: -5752433.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 248/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -5119440.0000 - mean_squared_error: 0.5793 - val_loss: -5775506.0000 - val_mean_squared_error: 0.6451\n",
            "Epoch 249/250\n",
            "1008/1008 [==============================] - 3s 3ms/step - loss: -5139906.5000 - mean_squared_error: 0.5793 - val_loss: -5798556.5000 - val_mean_squared_error: 0.6451\n",
            "Epoch 250/250\n",
            "1008/1008 [==============================] - 4s 4ms/step - loss: -5160323.0000 - mean_squared_error: 0.5793 - val_loss: -5821558.0000 - val_mean_squared_error: 0.6451\n",
            "470/470 [==============================] - 1s 3ms/step - loss: -5385386.5000 - mean_squared_error: 0.6010\n",
            "mean_squared_error: 60.10%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'mean_squared_error', 'val_loss', 'val_mean_squared_error'])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "3KPNage9ieMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history[\"mean_squared_error\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"model mean squared error\")\n",
        "plt.ylabel(\"mean_squared_error\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\",\"test\"],loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "--MXZfpEiMRN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "e74553be-f46b-4a96-c43c-b1ae3a3278ec"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### We obtained the best possible and acceptable accuracy with the MLP regressor."
      ],
      "metadata": {
        "id": "0Qm4a5YVitRB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tdsXdWricfel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem- 2)"
      ],
      "metadata": {
        "id": "qLfJDMyxjCwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded= files.upload()"
      ],
      "metadata": {
        "id": "EMFWlhDBjISp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "ec538d2d-0310-41bb-b9a7-e10110df2024"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f95c07bf-4f42-450a-990f-9376581a5a3e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f95c07bf-4f42-450a-990f-9376581a5a3e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving forestfires (1).csv to forestfires (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forestfires= pd.read_csv('forestfires (1).csv')\n",
        "forestfires"
      ],
      "metadata": {
        "id": "l9l7iAf6jxz_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "7fbecee2-6508-4920-f193-7af5ce2a748e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
              "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
              "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
              "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
              "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
              "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
              "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
              "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
              "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
              "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
              "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
              "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
              "\n",
              "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
              "0           0         0         0         1         0         0         0   \n",
              "1           0         0         0         0         0         0         1   \n",
              "2           0         0         0         0         0         0         1   \n",
              "3           0         0         0         1         0         0         0   \n",
              "4           0         0         0         1         0         0         0   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "512         0         0         0         0         0         0         0   \n",
              "513         0         0         0         0         0         0         0   \n",
              "514         0         0         0         0         0         0         0   \n",
              "515         0         0         0         0         0         0         0   \n",
              "516         0         0         0         0         0         1         0   \n",
              "\n",
              "     monthsep  size_category  \n",
              "0           0          small  \n",
              "1           0          small  \n",
              "2           0          small  \n",
              "3           0          small  \n",
              "4           0          small  \n",
              "..        ...            ...  \n",
              "512         0          large  \n",
              "513         0          large  \n",
              "514         0          large  \n",
              "515         0          small  \n",
              "516         0          small  \n",
              "\n",
              "[517 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f94ae0de-b6a4-480f-8b12-ffb5b5736386\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>...</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>oct</td>\n",
              "      <td>tue</td>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>oct</td>\n",
              "      <td>sat</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mar</td>\n",
              "      <td>sun</td>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>27.8</td>\n",
              "      <td>32</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.9</td>\n",
              "      <td>71</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.2</td>\n",
              "      <td>70</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>aug</td>\n",
              "      <td>sat</td>\n",
              "      <td>94.4</td>\n",
              "      <td>146.0</td>\n",
              "      <td>614.7</td>\n",
              "      <td>11.3</td>\n",
              "      <td>25.6</td>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>nov</td>\n",
              "      <td>tue</td>\n",
              "      <td>79.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>106.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>31</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f94ae0de-b6a4-480f-8b12-ffb5b5736386')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f94ae0de-b6a4-480f-8b12-ffb5b5736386 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f94ae0de-b6a4-480f-8b12-ffb5b5736386');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "enLPwfVwj-ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forestfires.info()"
      ],
      "metadata": {
        "id": "mPWzBn-Ojtfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c706a9-5c33-4f3f-f864-ecd3d5f39510"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 517 entries, 0 to 516\n",
            "Data columns (total 31 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   month          517 non-null    object \n",
            " 1   day            517 non-null    object \n",
            " 2   FFMC           517 non-null    float64\n",
            " 3   DMC            517 non-null    float64\n",
            " 4   DC             517 non-null    float64\n",
            " 5   ISI            517 non-null    float64\n",
            " 6   temp           517 non-null    float64\n",
            " 7   RH             517 non-null    int64  \n",
            " 8   wind           517 non-null    float64\n",
            " 9   rain           517 non-null    float64\n",
            " 10  area           517 non-null    float64\n",
            " 11  dayfri         517 non-null    int64  \n",
            " 12  daymon         517 non-null    int64  \n",
            " 13  daysat         517 non-null    int64  \n",
            " 14  daysun         517 non-null    int64  \n",
            " 15  daythu         517 non-null    int64  \n",
            " 16  daytue         517 non-null    int64  \n",
            " 17  daywed         517 non-null    int64  \n",
            " 18  monthapr       517 non-null    int64  \n",
            " 19  monthaug       517 non-null    int64  \n",
            " 20  monthdec       517 non-null    int64  \n",
            " 21  monthfeb       517 non-null    int64  \n",
            " 22  monthjan       517 non-null    int64  \n",
            " 23  monthjul       517 non-null    int64  \n",
            " 24  monthjun       517 non-null    int64  \n",
            " 25  monthmar       517 non-null    int64  \n",
            " 26  monthmay       517 non-null    int64  \n",
            " 27  monthnov       517 non-null    int64  \n",
            " 28  monthoct       517 non-null    int64  \n",
            " 29  monthsep       517 non-null    int64  \n",
            " 30  size_category  517 non-null    object \n",
            "dtypes: float64(8), int64(20), object(3)\n",
            "memory usage: 125.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forestfires.duplicated().value_counts()"
      ],
      "metadata": {
        "id": "a7OmkNaykB-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c64b0b0f-1c0b-42d3-b552-722c91dc34b1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    509\n",
              "True       8\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forestfires[forestfires.duplicated()]"
      ],
      "metadata": {
        "id": "7hsxPJskkB6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "5c76566e-bf13-4226-f101-9731e9bbfe2e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
              "53    aug  wed  92.1  111.2  654.1   9.6  20.4  42   4.9   0.0  ...         0   \n",
              "100   aug  sun  91.4  142.4  601.4  10.6  19.8  39   5.4   0.0  ...         0   \n",
              "215   mar  sat  91.7   35.8   80.8   7.8  17.0  27   4.9   0.0  ...         0   \n",
              "303   jun  fri  91.1   94.1  232.1   7.1  19.2  38   4.5   0.0  ...         0   \n",
              "426   aug  thu  91.6  248.4  753.8   6.3  20.4  56   2.2   0.0  ...         0   \n",
              "461   aug  sat  93.7  231.1  715.1   8.4  18.9  64   4.9   0.0  ...         0   \n",
              "501   aug  tue  96.1  181.1  671.2  14.3  21.6  65   4.9   0.8  ...         0   \n",
              "508   aug  fri  91.0  166.9  752.6   7.1  25.9  41   3.6   0.0  ...         0   \n",
              "\n",
              "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
              "53          0         0         0         0         0         0         0   \n",
              "100         0         0         0         0         0         0         0   \n",
              "215         0         0         0         1         0         0         0   \n",
              "303         0         0         1         0         0         0         0   \n",
              "426         0         0         0         0         0         0         0   \n",
              "461         0         0         0         0         0         0         0   \n",
              "501         0         0         0         0         0         0         0   \n",
              "508         0         0         0         0         0         0         0   \n",
              "\n",
              "     monthsep  size_category  \n",
              "53          0          small  \n",
              "100         0          small  \n",
              "215         0          large  \n",
              "303         0          small  \n",
              "426         0          small  \n",
              "461         0          small  \n",
              "501         0          small  \n",
              "508         0          small  \n",
              "\n",
              "[8 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ecab1f38-b2fb-43fe-9060-0b9dc8396c43\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>...</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>aug</td>\n",
              "      <td>wed</td>\n",
              "      <td>92.1</td>\n",
              "      <td>111.2</td>\n",
              "      <td>654.1</td>\n",
              "      <td>9.6</td>\n",
              "      <td>20.4</td>\n",
              "      <td>42</td>\n",
              "      <td>4.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>91.4</td>\n",
              "      <td>142.4</td>\n",
              "      <td>601.4</td>\n",
              "      <td>10.6</td>\n",
              "      <td>19.8</td>\n",
              "      <td>39</td>\n",
              "      <td>5.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>mar</td>\n",
              "      <td>sat</td>\n",
              "      <td>91.7</td>\n",
              "      <td>35.8</td>\n",
              "      <td>80.8</td>\n",
              "      <td>7.8</td>\n",
              "      <td>17.0</td>\n",
              "      <td>27</td>\n",
              "      <td>4.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>jun</td>\n",
              "      <td>fri</td>\n",
              "      <td>91.1</td>\n",
              "      <td>94.1</td>\n",
              "      <td>232.1</td>\n",
              "      <td>7.1</td>\n",
              "      <td>19.2</td>\n",
              "      <td>38</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>aug</td>\n",
              "      <td>thu</td>\n",
              "      <td>91.6</td>\n",
              "      <td>248.4</td>\n",
              "      <td>753.8</td>\n",
              "      <td>6.3</td>\n",
              "      <td>20.4</td>\n",
              "      <td>56</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>aug</td>\n",
              "      <td>sat</td>\n",
              "      <td>93.7</td>\n",
              "      <td>231.1</td>\n",
              "      <td>715.1</td>\n",
              "      <td>8.4</td>\n",
              "      <td>18.9</td>\n",
              "      <td>64</td>\n",
              "      <td>4.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>aug</td>\n",
              "      <td>tue</td>\n",
              "      <td>96.1</td>\n",
              "      <td>181.1</td>\n",
              "      <td>671.2</td>\n",
              "      <td>14.3</td>\n",
              "      <td>21.6</td>\n",
              "      <td>65</td>\n",
              "      <td>4.9</td>\n",
              "      <td>0.8</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>aug</td>\n",
              "      <td>fri</td>\n",
              "      <td>91.0</td>\n",
              "      <td>166.9</td>\n",
              "      <td>752.6</td>\n",
              "      <td>7.1</td>\n",
              "      <td>25.9</td>\n",
              "      <td>41</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecab1f38-b2fb-43fe-9060-0b9dc8396c43')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ecab1f38-b2fb-43fe-9060-0b9dc8396c43 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ecab1f38-b2fb-43fe-9060-0b9dc8396c43');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Droping duplicated records from dataset\n",
        "ffires_nodup=forestfires.copy()\n",
        "ffires_nodup=forestfires.drop_duplicates().reset_index()\n",
        "ffires_nodup=ffires_nodup.drop('index',axis=1)\n",
        "ffires_nodup"
      ],
      "metadata": {
        "id": "bZ2FH1l3kB3F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "fb213f4f-c24b-4515-c1ac-dcc076be3eac"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
              "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
              "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
              "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
              "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
              "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
              "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
              "504   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
              "505   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
              "506   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
              "507   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
              "508   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
              "\n",
              "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
              "0           0         0         0         1         0         0         0   \n",
              "1           0         0         0         0         0         0         1   \n",
              "2           0         0         0         0         0         0         1   \n",
              "3           0         0         0         1         0         0         0   \n",
              "4           0         0         0         1         0         0         0   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "504         0         0         0         0         0         0         0   \n",
              "505         0         0         0         0         0         0         0   \n",
              "506         0         0         0         0         0         0         0   \n",
              "507         0         0         0         0         0         0         0   \n",
              "508         0         0         0         0         0         1         0   \n",
              "\n",
              "     monthsep  size_category  \n",
              "0           0          small  \n",
              "1           0          small  \n",
              "2           0          small  \n",
              "3           0          small  \n",
              "4           0          small  \n",
              "..        ...            ...  \n",
              "504         0          large  \n",
              "505         0          large  \n",
              "506         0          large  \n",
              "507         0          small  \n",
              "508         0          small  \n",
              "\n",
              "[509 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8ed3607-128d-4aad-882c-1261d288d8dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>...</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>oct</td>\n",
              "      <td>tue</td>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>oct</td>\n",
              "      <td>sat</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mar</td>\n",
              "      <td>sun</td>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>27.8</td>\n",
              "      <td>32</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.9</td>\n",
              "      <td>71</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.2</td>\n",
              "      <td>70</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>aug</td>\n",
              "      <td>sat</td>\n",
              "      <td>94.4</td>\n",
              "      <td>146.0</td>\n",
              "      <td>614.7</td>\n",
              "      <td>11.3</td>\n",
              "      <td>25.6</td>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>nov</td>\n",
              "      <td>tue</td>\n",
              "      <td>79.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>106.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>31</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>509 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8ed3607-128d-4aad-882c-1261d288d8dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e8ed3607-128d-4aad-882c-1261d288d8dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e8ed3607-128d-4aad-882c-1261d288d8dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ffires_nodup.describe()"
      ],
      "metadata": {
        "id": "X5HJSJ-ikMz-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "40a03a0f-0fce-485b-d07a-60a6fcc3e01e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
              "count  509.000000  509.000000  509.000000  509.000000  509.000000  509.000000   \n",
              "mean    90.618075  110.235756  547.787623    9.023576   18.865422   44.253438   \n",
              "std      5.555527   63.804112  248.196222    4.585083    5.841083   16.365192   \n",
              "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
              "25%     90.200000   62.300000  437.700000    6.400000   15.400000   32.000000   \n",
              "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
              "75%     92.900000  141.300000  713.900000   11.000000   22.800000   53.000000   \n",
              "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
              "\n",
              "             wind        rain         area      dayfri  ...    monthdec  \\\n",
              "count  509.000000  509.000000   509.000000  509.000000  ...  509.000000   \n",
              "mean     4.011395    0.020432    12.992908    0.163065  ...    0.017682   \n",
              "std      1.800926    0.296261    64.133357    0.369788  ...    0.131921   \n",
              "min      0.400000    0.000000     0.000000    0.000000  ...    0.000000   \n",
              "25%      2.700000    0.000000     0.000000    0.000000  ...    0.000000   \n",
              "50%      4.000000    0.000000     0.610000    0.000000  ...    0.000000   \n",
              "75%      4.900000    0.000000     6.580000    0.000000  ...    0.000000   \n",
              "max      9.400000    6.400000  1090.840000    1.000000  ...    1.000000   \n",
              "\n",
              "         monthfeb    monthjan    monthjul    monthjun    monthmar    monthmay  \\\n",
              "count  509.000000  509.000000  509.000000  509.000000  509.000000  509.000000   \n",
              "mean     0.039293    0.003929    0.062868    0.031434    0.104126    0.003929   \n",
              "std      0.194482    0.062622    0.242965    0.174660    0.305724    0.062622   \n",
              "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
              "\n",
              "         monthnov    monthoct    monthsep  \n",
              "count  509.000000  509.000000  509.000000  \n",
              "mean     0.001965    0.029470    0.337917  \n",
              "std      0.044324    0.169285    0.473466  \n",
              "min      0.000000    0.000000    0.000000  \n",
              "25%      0.000000    0.000000    0.000000  \n",
              "50%      0.000000    0.000000    0.000000  \n",
              "75%      0.000000    0.000000    1.000000  \n",
              "max      1.000000    1.000000    1.000000  \n",
              "\n",
              "[8 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c532fb9-1ce1-4fc2-b5b5-d7fd1ce01d2e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>...</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>509.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>90.618075</td>\n",
              "      <td>110.235756</td>\n",
              "      <td>547.787623</td>\n",
              "      <td>9.023576</td>\n",
              "      <td>18.865422</td>\n",
              "      <td>44.253438</td>\n",
              "      <td>4.011395</td>\n",
              "      <td>0.020432</td>\n",
              "      <td>12.992908</td>\n",
              "      <td>0.163065</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017682</td>\n",
              "      <td>0.039293</td>\n",
              "      <td>0.003929</td>\n",
              "      <td>0.062868</td>\n",
              "      <td>0.031434</td>\n",
              "      <td>0.104126</td>\n",
              "      <td>0.003929</td>\n",
              "      <td>0.001965</td>\n",
              "      <td>0.029470</td>\n",
              "      <td>0.337917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.555527</td>\n",
              "      <td>63.804112</td>\n",
              "      <td>248.196222</td>\n",
              "      <td>4.585083</td>\n",
              "      <td>5.841083</td>\n",
              "      <td>16.365192</td>\n",
              "      <td>1.800926</td>\n",
              "      <td>0.296261</td>\n",
              "      <td>64.133357</td>\n",
              "      <td>0.369788</td>\n",
              "      <td>...</td>\n",
              "      <td>0.131921</td>\n",
              "      <td>0.194482</td>\n",
              "      <td>0.062622</td>\n",
              "      <td>0.242965</td>\n",
              "      <td>0.174660</td>\n",
              "      <td>0.305724</td>\n",
              "      <td>0.062622</td>\n",
              "      <td>0.044324</td>\n",
              "      <td>0.169285</td>\n",
              "      <td>0.473466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>18.700000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>7.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>90.200000</td>\n",
              "      <td>62.300000</td>\n",
              "      <td>437.700000</td>\n",
              "      <td>6.400000</td>\n",
              "      <td>15.400000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>91.600000</td>\n",
              "      <td>108.300000</td>\n",
              "      <td>664.200000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>19.300000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>92.900000</td>\n",
              "      <td>141.300000</td>\n",
              "      <td>713.900000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>22.800000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.580000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>96.200000</td>\n",
              "      <td>291.300000</td>\n",
              "      <td>860.600000</td>\n",
              "      <td>56.100000</td>\n",
              "      <td>33.300000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>6.400000</td>\n",
              "      <td>1090.840000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 28 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c532fb9-1ce1-4fc2-b5b5-d7fd1ce01d2e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c532fb9-1ce1-4fc2-b5b5-d7fd1ce01d2e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c532fb9-1ce1-4fc2-b5b5-d7fd1ce01d2e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label Encoding"
      ],
      "metadata": {
        "id": "W1t4lOEikToW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "ffires_lab=ffires_nodup.copy()\n",
        "for i, column in enumerate(ffires_lab[[feature for feature in ffires_lab.columns if ffires_lab[feature].dtypes == 'O']].columns, 1):\n",
        "  label_encoder=preprocessing.LabelEncoder()\n",
        "  ffires_lab[column]=label_encoder.fit_transform(ffires_lab[column])\n",
        "ffires_lab"
      ],
      "metadata": {
        "id": "E15tpYOwkMjm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "629c58a3-987f-4391-98e2-107b7a4b4ed6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  \\\n",
              "0        7    0  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...   \n",
              "1       10    5  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...   \n",
              "2       10    2  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...   \n",
              "3        7    0  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...   \n",
              "4        7    3  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...   \n",
              "..     ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...   \n",
              "504      1    3  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...   \n",
              "505      1    3  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...   \n",
              "506      1    3  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...   \n",
              "507      1    2  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...   \n",
              "508      9    5  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...   \n",
              "\n",
              "     monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
              "0           0         0         0         0         1         0         0   \n",
              "1           0         0         0         0         0         0         0   \n",
              "2           0         0         0         0         0         0         0   \n",
              "3           0         0         0         0         1         0         0   \n",
              "4           0         0         0         0         1         0         0   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "504         0         0         0         0         0         0         0   \n",
              "505         0         0         0         0         0         0         0   \n",
              "506         0         0         0         0         0         0         0   \n",
              "507         0         0         0         0         0         0         0   \n",
              "508         0         0         0         0         0         0         1   \n",
              "\n",
              "     monthoct  monthsep  size_category  \n",
              "0           0         0              1  \n",
              "1           1         0              1  \n",
              "2           1         0              1  \n",
              "3           0         0              1  \n",
              "4           0         0              1  \n",
              "..        ...       ...            ...  \n",
              "504         0         0              0  \n",
              "505         0         0              0  \n",
              "506         0         0              0  \n",
              "507         0         0              1  \n",
              "508         0         0              1  \n",
              "\n",
              "[509 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76d42275-424b-44ee-97f9-c3e2a23994b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>...</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>27.8</td>\n",
              "      <td>32</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.9</td>\n",
              "      <td>71</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.2</td>\n",
              "      <td>70</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>94.4</td>\n",
              "      <td>146.0</td>\n",
              "      <td>614.7</td>\n",
              "      <td>11.3</td>\n",
              "      <td>25.6</td>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>79.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>106.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>31</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>509 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76d42275-424b-44ee-97f9-c3e2a23994b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76d42275-424b-44ee-97f9-c3e2a23994b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76d42275-424b-44ee-97f9-c3e2a23994b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standardizing Data"
      ],
      "metadata": {
        "id": "RnHKM4iekbQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "std=StandardScaler()\n",
        "ffires_std=ffires_lab.copy()\n",
        "std.fit_transform(ffires_std)"
      ],
      "metadata": {
        "id": "vnWh6OSFkMZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8331dd98-e2dd-4d7c-ca09-59f2bdb1c931"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.71858196e-01, -1.42449474e+00, -7.96039810e-01, ...,\n",
              "        -1.74253759e-01, -7.14412875e-01,  6.09891511e-01],\n",
              "       [ 9.58019296e-01,  1.17804590e+00, -3.25665522e-03, ...,\n",
              "         5.73875712e+00, -7.14412875e-01,  6.09891511e-01],\n",
              "       [ 9.58019296e-01, -3.83478484e-01, -3.25665522e-03, ...,\n",
              "         5.73875712e+00, -7.14412875e-01,  6.09891511e-01],\n",
              "       ...,\n",
              "       [-1.10046400e+00,  1.37029645e-01, -1.62485856e+00, ...,\n",
              "        -1.74253759e-01, -7.14412875e-01, -1.63963587e+00],\n",
              "       [-1.10046400e+00, -3.83478484e-01,  6.81419706e-01, ...,\n",
              "        -1.74253759e-01, -7.14412875e-01,  6.09891511e-01],\n",
              "       [ 7.29298930e-01,  1.17804590e+00, -2.00323234e+00, ...,\n",
              "        -1.74253759e-01, -7.14412875e-01,  6.09891511e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ffires_std=pd.DataFrame(std.fit_transform(ffires_std),columns=ffires_lab.columns)\n",
        "ffires_std"
      ],
      "metadata": {
        "id": "M2DAd3A5khg2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "80738f8c-bfc9-40dc-c0f8-9660771e940b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        month       day      FFMC       DMC        DC       ISI      temp  \\\n",
              "0    0.271858 -1.424495 -0.796040 -1.318386 -1.828931 -0.856568 -1.827729   \n",
              "1    0.958019  1.178046 -0.003257 -1.174053  0.489257 -0.507267 -0.148307   \n",
              "2    0.958019 -0.383478 -0.003257 -1.043839  0.561045 -0.507267 -0.730964   \n",
              "3    0.271858 -1.424495  0.194939 -1.206998 -1.896686 -0.005147 -1.810592   \n",
              "4    0.271858  0.137030 -0.237488 -0.924607 -1.797070  0.125841 -1.279346   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "504 -1.100464  0.137030 -1.624859 -0.839890  0.475141 -1.555170  1.531115   \n",
              "505 -1.100464  0.137030 -1.624859 -0.839890  0.475141 -1.555170  0.520034   \n",
              "506 -1.100464  0.137030 -1.624859 -0.839890  0.475141 -1.555170  0.400076   \n",
              "507 -1.100464 -0.383478  0.681420  0.561083  0.269860  0.496973  1.154102   \n",
              "508  0.729299  1.178046 -2.003232 -1.682356 -1.778921 -1.729820 -1.210798   \n",
              "\n",
              "           RH      wind      rain  ...  monthfeb  monthjan  monthjul  \\\n",
              "0    0.412656  1.494370 -0.069035  ... -0.202237 -0.062807  -0.25901   \n",
              "1   -0.688321 -1.729364 -0.069035  ... -0.202237 -0.062807  -0.25901   \n",
              "2   -0.688321 -1.507037 -0.069035  ... -0.202237 -0.062807  -0.25901   \n",
              "3    3.226265 -0.006333  0.606709  ... -0.202237 -0.062807  -0.25901   \n",
              "4    3.348596 -1.229129 -0.069035  ... -0.202237 -0.062807  -0.25901   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "504 -0.749487 -0.728894 -0.069035  ... -0.202237 -0.062807  -0.25901   \n",
              "505  1.635965  0.994136 -0.069035  ... -0.202237 -0.062807  -0.25901   \n",
              "506  1.574799  1.494370 -0.069035  ... -0.202237 -0.062807  -0.25901   \n",
              "507 -0.137832 -0.006333 -0.069035  ... -0.202237 -0.062807  -0.25901   \n",
              "508 -0.810652  0.271575 -0.069035  ... -0.202237 -0.062807  -0.25901   \n",
              "\n",
              "     monthjun  monthmar  monthmay   monthnov  monthoct  monthsep  \\\n",
              "0   -0.180151  2.933219 -0.062807  -0.044368 -0.174254 -0.714413   \n",
              "1   -0.180151 -0.340922 -0.062807  -0.044368  5.738757 -0.714413   \n",
              "2   -0.180151 -0.340922 -0.062807  -0.044368  5.738757 -0.714413   \n",
              "3   -0.180151  2.933219 -0.062807  -0.044368 -0.174254 -0.714413   \n",
              "4   -0.180151  2.933219 -0.062807  -0.044368 -0.174254 -0.714413   \n",
              "..        ...       ...       ...        ...       ...       ...   \n",
              "504 -0.180151 -0.340922 -0.062807  -0.044368 -0.174254 -0.714413   \n",
              "505 -0.180151 -0.340922 -0.062807  -0.044368 -0.174254 -0.714413   \n",
              "506 -0.180151 -0.340922 -0.062807  -0.044368 -0.174254 -0.714413   \n",
              "507 -0.180151 -0.340922 -0.062807  -0.044368 -0.174254 -0.714413   \n",
              "508 -0.180151 -0.340922 -0.062807  22.538855 -0.174254 -0.714413   \n",
              "\n",
              "     size_category  \n",
              "0         0.609892  \n",
              "1         0.609892  \n",
              "2         0.609892  \n",
              "3         0.609892  \n",
              "4         0.609892  \n",
              "..             ...  \n",
              "504      -1.639636  \n",
              "505      -1.639636  \n",
              "506      -1.639636  \n",
              "507       0.609892  \n",
              "508       0.609892  \n",
              "\n",
              "[509 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f51d5348-a4d9-48af-9ccd-53f2fb2c426a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>...</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.271858</td>\n",
              "      <td>-1.424495</td>\n",
              "      <td>-0.796040</td>\n",
              "      <td>-1.318386</td>\n",
              "      <td>-1.828931</td>\n",
              "      <td>-0.856568</td>\n",
              "      <td>-1.827729</td>\n",
              "      <td>0.412656</td>\n",
              "      <td>1.494370</td>\n",
              "      <td>-0.069035</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.202237</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.25901</td>\n",
              "      <td>-0.180151</td>\n",
              "      <td>2.933219</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.044368</td>\n",
              "      <td>-0.174254</td>\n",
              "      <td>-0.714413</td>\n",
              "      <td>0.609892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.958019</td>\n",
              "      <td>1.178046</td>\n",
              "      <td>-0.003257</td>\n",
              "      <td>-1.174053</td>\n",
              "      <td>0.489257</td>\n",
              "      <td>-0.507267</td>\n",
              "      <td>-0.148307</td>\n",
              "      <td>-0.688321</td>\n",
              "      <td>-1.729364</td>\n",
              "      <td>-0.069035</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.202237</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.25901</td>\n",
              "      <td>-0.180151</td>\n",
              "      <td>-0.340922</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.044368</td>\n",
              "      <td>5.738757</td>\n",
              "      <td>-0.714413</td>\n",
              "      <td>0.609892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.958019</td>\n",
              "      <td>-0.383478</td>\n",
              "      <td>-0.003257</td>\n",
              "      <td>-1.043839</td>\n",
              "      <td>0.561045</td>\n",
              "      <td>-0.507267</td>\n",
              "      <td>-0.730964</td>\n",
              "      <td>-0.688321</td>\n",
              "      <td>-1.507037</td>\n",
              "      <td>-0.069035</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.202237</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.25901</td>\n",
              "      <td>-0.180151</td>\n",
              "      <td>-0.340922</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.044368</td>\n",
              "      <td>5.738757</td>\n",
              "      <td>-0.714413</td>\n",
              "      <td>0.609892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.271858</td>\n",
              "      <td>-1.424495</td>\n",
              "      <td>0.194939</td>\n",
              "      <td>-1.206998</td>\n",
              "      <td>-1.896686</td>\n",
              "      <td>-0.005147</td>\n",
              "      <td>-1.810592</td>\n",
              "      <td>3.226265</td>\n",
              "      <td>-0.006333</td>\n",
              "      <td>0.606709</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.202237</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.25901</td>\n",
              "      <td>-0.180151</td>\n",
              "      <td>2.933219</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.044368</td>\n",
              "      <td>-0.174254</td>\n",
              "      <td>-0.714413</td>\n",
              "      <td>0.609892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.271858</td>\n",
              "      <td>0.137030</td>\n",
              "      <td>-0.237488</td>\n",
              "      <td>-0.924607</td>\n",
              "      <td>-1.797070</td>\n",
              "      <td>0.125841</td>\n",
              "      <td>-1.279346</td>\n",
              "      <td>3.348596</td>\n",
              "      <td>-1.229129</td>\n",
              "      <td>-0.069035</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.202237</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.25901</td>\n",
              "      <td>-0.180151</td>\n",
              "      <td>2.933219</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.044368</td>\n",
              "      <td>-0.174254</td>\n",
              "      <td>-0.714413</td>\n",
              "      <td>0.609892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>-1.100464</td>\n",
              "      <td>0.137030</td>\n",
              "      <td>-1.624859</td>\n",
              "      <td>-0.839890</td>\n",
              "      <td>0.475141</td>\n",
              "      <td>-1.555170</td>\n",
              "      <td>1.531115</td>\n",
              "      <td>-0.749487</td>\n",
              "      <td>-0.728894</td>\n",
              "      <td>-0.069035</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.202237</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.25901</td>\n",
              "      <td>-0.180151</td>\n",
              "      <td>-0.340922</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.044368</td>\n",
              "      <td>-0.174254</td>\n",
              "      <td>-0.714413</td>\n",
              "      <td>-1.639636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>-1.100464</td>\n",
              "      <td>0.137030</td>\n",
              "      <td>-1.624859</td>\n",
              "      <td>-0.839890</td>\n",
              "      <td>0.475141</td>\n",
              "      <td>-1.555170</td>\n",
              "      <td>0.520034</td>\n",
              "      <td>1.635965</td>\n",
              "      <td>0.994136</td>\n",
              "      <td>-0.069035</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.202237</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.25901</td>\n",
              "      <td>-0.180151</td>\n",
              "      <td>-0.340922</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.044368</td>\n",
              "      <td>-0.174254</td>\n",
              "      <td>-0.714413</td>\n",
              "      <td>-1.639636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>-1.100464</td>\n",
              "      <td>0.137030</td>\n",
              "      <td>-1.624859</td>\n",
              "      <td>-0.839890</td>\n",
              "      <td>0.475141</td>\n",
              "      <td>-1.555170</td>\n",
              "      <td>0.400076</td>\n",
              "      <td>1.574799</td>\n",
              "      <td>1.494370</td>\n",
              "      <td>-0.069035</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.202237</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.25901</td>\n",
              "      <td>-0.180151</td>\n",
              "      <td>-0.340922</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.044368</td>\n",
              "      <td>-0.174254</td>\n",
              "      <td>-0.714413</td>\n",
              "      <td>-1.639636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>-1.100464</td>\n",
              "      <td>-0.383478</td>\n",
              "      <td>0.681420</td>\n",
              "      <td>0.561083</td>\n",
              "      <td>0.269860</td>\n",
              "      <td>0.496973</td>\n",
              "      <td>1.154102</td>\n",
              "      <td>-0.137832</td>\n",
              "      <td>-0.006333</td>\n",
              "      <td>-0.069035</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.202237</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.25901</td>\n",
              "      <td>-0.180151</td>\n",
              "      <td>-0.340922</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.044368</td>\n",
              "      <td>-0.174254</td>\n",
              "      <td>-0.714413</td>\n",
              "      <td>0.609892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>0.729299</td>\n",
              "      <td>1.178046</td>\n",
              "      <td>-2.003232</td>\n",
              "      <td>-1.682356</td>\n",
              "      <td>-1.778921</td>\n",
              "      <td>-1.729820</td>\n",
              "      <td>-1.210798</td>\n",
              "      <td>-0.810652</td>\n",
              "      <td>0.271575</td>\n",
              "      <td>-0.069035</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.202237</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>-0.25901</td>\n",
              "      <td>-0.180151</td>\n",
              "      <td>-0.340922</td>\n",
              "      <td>-0.062807</td>\n",
              "      <td>22.538855</td>\n",
              "      <td>-0.174254</td>\n",
              "      <td>-0.714413</td>\n",
              "      <td>0.609892</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>509 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f51d5348-a4d9-48af-9ccd-53f2fb2c426a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f51d5348-a4d9-48af-9ccd-53f2fb2c426a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f51d5348-a4d9-48af-9ccd-53f2fb2c426a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Splitting"
      ],
      "metadata": {
        "id": "VSj9lRgykmhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=ffires_std.drop('size_category',axis=1)\n",
        "y=ffires_std['size_category']"
      ],
      "metadata": {
        "id": "qmchhuQTkhbP"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
        "x_train.shape, x_test.shape,y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "84glndvTkhVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3dd35dd-43ae-49be-c401-4baa32c2c62e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((341, 30), (168, 30), (341,), (168,))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning of Hyperparameters:"
      ],
      "metadata": {
        "id": "QMDoWjJ5kvwc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Batch Size\n",
        "\n",
        "###### Epochs"
      ],
      "metadata": {
        "id": "XCajKfWEk2Ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# libs\n",
        "import tensorflow\n",
        "from sklearn.model_selection import GridSearchCV,KFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "#optimizers\n",
        "from keras.optimizers import adam\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "7n8Fl-x4khPy"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model def creation\n",
        "def create_model():\n",
        "    model = Sequential(name='Hypterparameter-Tuning-Dummy')\n",
        "    model.add(Dense(12, input_dim=30, kernel_initializer='uniform', activation='relu'))\n",
        "    model.add(Dense(8,kernel_initializer='uniform', activation='relu'))\n",
        "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "    \n",
        "    adam=Adam(learning_rate=0.01)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "yNulmo2Mkt6t"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model\n",
        "model=KerasClassifier(build_fn=create_model,verbose=0)\n",
        "#hyper param \n",
        "batch_size=[10,20]\n",
        "epochs=[10,20,50]\n",
        "# Make a dictionary of the grid search parameters\n",
        "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
        "# Build and fit the GridSearchCV\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(x,y)"
      ],
      "metadata": {
        "id": "LRs0YwGDlFy_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46637a67-aae0-46fd-dd04-2bd0fe084631"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "[CV 1/5; 1/6] START batch_size=10, epochs=10....................................\n",
            "[CV 1/5; 1/6] END .....batch_size=10, epochs=10;, score=0.980 total time=   2.8s\n",
            "[CV 2/5; 1/6] START batch_size=10, epochs=10....................................\n",
            "[CV 2/5; 1/6] END .....batch_size=10, epochs=10;, score=0.863 total time=   2.2s\n",
            "[CV 3/5; 1/6] START batch_size=10, epochs=10....................................\n",
            "[CV 3/5; 1/6] END .....batch_size=10, epochs=10;, score=0.824 total time=   2.6s\n",
            "[CV 4/5; 1/6] START batch_size=10, epochs=10....................................\n",
            "[CV 4/5; 1/6] END .....batch_size=10, epochs=10;, score=0.853 total time=   3.9s\n",
            "[CV 5/5; 1/6] START batch_size=10, epochs=10....................................\n",
            "[CV 5/5; 1/6] END .....batch_size=10, epochs=10;, score=0.911 total time=   2.9s\n",
            "[CV 1/5; 2/6] START batch_size=10, epochs=20....................................\n",
            "[CV 1/5; 2/6] END .....batch_size=10, epochs=20;, score=0.990 total time=   4.1s\n",
            "[CV 2/5; 2/6] START batch_size=10, epochs=20....................................\n",
            "[CV 2/5; 2/6] END .....batch_size=10, epochs=20;, score=0.853 total time=   4.0s\n",
            "[CV 3/5; 2/6] START batch_size=10, epochs=20....................................\n",
            "[CV 3/5; 2/6] END .....batch_size=10, epochs=20;, score=0.902 total time=   3.9s\n",
            "[CV 4/5; 2/6] START batch_size=10, epochs=20....................................\n",
            "[CV 4/5; 2/6] END .....batch_size=10, epochs=20;, score=0.882 total time=   3.0s\n",
            "[CV 5/5; 2/6] START batch_size=10, epochs=20....................................\n",
            "[CV 5/5; 2/6] END .....batch_size=10, epochs=20;, score=0.891 total time=   3.1s\n",
            "[CV 1/5; 3/6] START batch_size=10, epochs=50....................................\n",
            "[CV 1/5; 3/6] END .....batch_size=10, epochs=50;, score=1.000 total time=   6.5s\n",
            "[CV 2/5; 3/6] START batch_size=10, epochs=50....................................\n",
            "[CV 2/5; 3/6] END .....batch_size=10, epochs=50;, score=0.853 total time=   5.4s\n",
            "[CV 3/5; 3/6] START batch_size=10, epochs=50....................................\n",
            "[CV 3/5; 3/6] END .....batch_size=10, epochs=50;, score=0.902 total time=   5.9s\n",
            "[CV 4/5; 3/6] START batch_size=10, epochs=50....................................\n",
            "[CV 4/5; 3/6] END .....batch_size=10, epochs=50;, score=0.902 total time=   6.4s\n",
            "[CV 5/5; 3/6] START batch_size=10, epochs=50....................................\n",
            "[CV 5/5; 3/6] END .....batch_size=10, epochs=50;, score=0.871 total time=   6.3s\n",
            "[CV 1/5; 4/6] START batch_size=20, epochs=10....................................\n",
            "[CV 1/5; 4/6] END .....batch_size=20, epochs=10;, score=0.971 total time=   1.8s\n",
            "[CV 2/5; 4/6] START batch_size=20, epochs=10....................................\n",
            "[CV 2/5; 4/6] END .....batch_size=20, epochs=10;, score=0.794 total time=   2.7s\n",
            "[CV 3/5; 4/6] START batch_size=20, epochs=10....................................\n",
            "[CV 3/5; 4/6] END .....batch_size=20, epochs=10;, score=0.794 total time=   2.1s\n",
            "[CV 4/5; 4/6] START batch_size=20, epochs=10....................................\n",
            "[CV 4/5; 4/6] END .....batch_size=20, epochs=10;, score=0.833 total time=   2.2s\n",
            "[CV 5/5; 4/6] START batch_size=20, epochs=10....................................\n",
            "[CV 5/5; 4/6] END .....batch_size=20, epochs=10;, score=0.842 total time=   2.4s\n",
            "[CV 1/5; 5/6] START batch_size=20, epochs=20....................................\n",
            "[CV 1/5; 5/6] END .....batch_size=20, epochs=20;, score=1.000 total time=   2.4s\n",
            "[CV 2/5; 5/6] START batch_size=20, epochs=20....................................\n",
            "[CV 2/5; 5/6] END .....batch_size=20, epochs=20;, score=0.873 total time=   2.2s\n",
            "[CV 3/5; 5/6] START batch_size=20, epochs=20....................................\n",
            "[CV 3/5; 5/6] END .....batch_size=20, epochs=20;, score=0.873 total time=   2.1s\n",
            "[CV 4/5; 5/6] START batch_size=20, epochs=20....................................\n",
            "[CV 4/5; 5/6] END .....batch_size=20, epochs=20;, score=0.902 total time=   2.2s\n",
            "[CV 5/5; 5/6] START batch_size=20, epochs=20....................................\n",
            "[CV 5/5; 5/6] END .....batch_size=20, epochs=20;, score=0.871 total time=   3.1s\n",
            "[CV 1/5; 6/6] START batch_size=20, epochs=50....................................\n",
            "[CV 1/5; 6/6] END .....batch_size=20, epochs=50;, score=0.980 total time=   3.5s\n",
            "[CV 2/5; 6/6] START batch_size=20, epochs=50....................................\n",
            "[CV 2/5; 6/6] END .....batch_size=20, epochs=50;, score=0.853 total time=   3.5s\n",
            "[CV 3/5; 6/6] START batch_size=20, epochs=50....................................\n",
            "[CV 3/5; 6/6] END .....batch_size=20, epochs=50;, score=0.902 total time=   4.1s\n",
            "[CV 4/5; 6/6] START batch_size=20, epochs=50....................................\n",
            "[CV 4/5; 6/6] END .....batch_size=20, epochs=50;, score=0.873 total time=   3.8s\n",
            "[CV 5/5; 6/6] START batch_size=20, epochs=50....................................\n",
            "[CV 5/5; 6/6] END .....batch_size=20, epochs=50;, score=0.891 total time=   4.5s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning of Hyperparameters:- Learning rate and Drop out rate"
      ],
      "metadata": {
        "id": "SwnusltLlJjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dropout\n",
        "\n",
        "#model def\n",
        "def create_model(learning_rate,dropout_rate):\n",
        "  model=Sequential()\n",
        "  model.add(Dense(8,input_dim=30,kernel_initializer='normal',activation='relu'))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "  model.add(Dense(12,input_dim=8,kernel_initializer='normal',activation='relu'))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  adam=Adam(learning_rate=learning_rate)\n",
        "  model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "#model creation\n",
        "model=KerasClassifier(build_fn=create_model,verbose=0,batch_size=40,epochs=50)\n",
        "#grid search params\n",
        "learning_rate=[0.001,0.01,0.1]\n",
        "dropout_rate=[0.0,0.1,0.2]\n",
        "#grid search dictionary\n",
        "param_grids=dict(learning_rate=learning_rate,dropout_rate=dropout_rate)\n",
        "\n",
        "#gridsearch cv fit\n",
        "grid=GridSearchCV(estimator=model,param_grid=param_grids,cv=KFold(),verbose=10)\n",
        "grid_result=grid.fit(x,y)"
      ],
      "metadata": {
        "id": "hnpRfD15lFvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d0af6e-748b-427e-a291-b0b13d329447"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV 1/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
            "[CV 1/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=1.000 total time=   3.6s\n",
            "[CV 2/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
            "[CV 2/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.765 total time=   2.7s\n",
            "[CV 3/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
            "[CV 3/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.657 total time=   2.7s\n",
            "[CV 4/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8623a5fbe0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.814 total time=   4.0s\n",
            "[CV 5/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8629641a20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.743 total time=   2.9s\n",
            "[CV 1/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
            "[CV 1/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=1.000 total time=   2.6s\n",
            "[CV 2/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
            "[CV 2/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.833 total time=   3.9s\n",
            "[CV 3/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
            "[CV 3/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.882 total time=   3.9s\n",
            "[CV 4/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
            "[CV 4/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.902 total time=   2.7s\n",
            "[CV 5/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
            "[CV 5/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.861 total time=   2.6s\n",
            "[CV 1/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
            "[CV 1/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.990 total time=   2.6s\n",
            "[CV 2/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
            "[CV 2/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.892 total time=   3.3s\n",
            "[CV 3/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
            "[CV 3/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.902 total time=   5.0s\n",
            "[CV 4/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
            "[CV 4/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.882 total time=   3.0s\n",
            "[CV 5/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
            "[CV 5/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.871 total time=   3.4s\n",
            "[CV 1/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
            "[CV 1/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.961 total time=   4.1s\n",
            "[CV 2/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
            "[CV 2/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.765 total time=   4.1s\n",
            "[CV 3/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
            "[CV 3/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.696 total time=   4.0s\n",
            "[CV 4/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
            "[CV 4/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.686 total time=   4.1s\n",
            "[CV 5/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
            "[CV 5/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.772 total time=   3.1s\n",
            "[CV 1/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
            "[CV 1/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=1.000 total time=   4.0s\n",
            "[CV 2/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
            "[CV 2/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.853 total time=   2.7s\n",
            "[CV 3/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
            "[CV 3/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.892 total time=   3.9s\n",
            "[CV 4/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
            "[CV 4/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.912 total time=   4.1s\n",
            "[CV 5/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
            "[CV 5/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.911 total time=   5.0s\n",
            "[CV 1/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
            "[CV 1/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.853 total time=   3.2s\n",
            "[CV 2/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
            "[CV 2/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.833 total time=   3.7s\n",
            "[CV 3/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
            "[CV 3/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.824 total time=   4.1s\n",
            "[CV 4/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
            "[CV 4/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.833 total time=   4.0s\n",
            "[CV 5/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
            "[CV 5/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.693 total time=   3.5s\n",
            "[CV 1/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
            "[CV 1/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=1.000 total time=   4.0s\n",
            "[CV 2/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
            "[CV 2/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.765 total time=   2.8s\n",
            "[CV 3/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
            "[CV 3/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.627 total time=   3.0s\n",
            "[CV 4/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
            "[CV 4/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.735 total time=   3.4s\n",
            "[CV 5/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
            "[CV 5/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.772 total time=   3.9s\n",
            "[CV 1/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
            "[CV 1/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=1.000 total time=   3.9s\n",
            "[CV 2/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
            "[CV 2/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.814 total time=   3.4s\n",
            "[CV 3/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
            "[CV 3/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.902 total time=   3.8s\n",
            "[CV 4/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
            "[CV 4/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.902 total time=   4.0s\n",
            "[CV 5/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
            "[CV 5/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.871 total time=   4.0s\n",
            "[CV 1/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
            "[CV 1/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=1.000 total time=   4.0s\n",
            "[CV 2/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
            "[CV 2/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.833 total time=   2.8s\n",
            "[CV 3/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
            "[CV 3/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.529 total time=   3.2s\n",
            "[CV 4/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
            "[CV 4/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.892 total time=   4.2s\n",
            "[CV 5/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
            "[CV 5/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.871 total time=   4.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#summarizing results\n",
        "print('Best:{},using{}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means=grid_result.cv_results_['mean_test_score']\n",
        "stds=grid_result.cv_results_['std_test_score']\n",
        "params=grid_result.cv_results_['params']\n",
        "for mean,stdev,param in zip(means,stds,params):\n",
        "  print('{},{} with:{}'.format(mean,stdev,param))"
      ],
      "metadata": {
        "id": "CtROSgHSlFtP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9db44237-d18f-45e5-cd9a-546766a07657"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best:0.9135507583618164,using{'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
            "0.7955736756324768,0.11412457311495978 with:{'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
            "0.895806634426117,0.05685564239197079 with:{'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
            "0.9075907468795776,0.04254042455043982 with:{'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
            "0.7760240793228149,0.09871653918933225 with:{'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
            "0.9135507583618164,0.04819742500824427 with:{'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
            "0.8072412967681885,0.05788024945082707 with:{'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
            "0.7799456477165222,0.12162512051227727 with:{'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "0.8977868318557739,0.06041675809900803 with:{'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
            "0.8252378106117249,0.15793611809722202 with:{'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning of Hyperparameters:- Activation Function and Kernel Initializer"
      ],
      "metadata": {
        "id": "zKdhVYfQlVgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model def\n",
        "def create_model(activation_function,init):\n",
        "  model=Sequential()\n",
        "  model.add(Dense(8,input_dim=30,kernel_initializer=init,activation=activation_function))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(12,input_dim=8,kernel_initializer=init,activation=activation_function))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  adam=Adam(learning_rate=0.001)\n",
        "  model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "#model creation\n",
        "model=KerasClassifier(build_fn=create_model,verbose=0,batch_size=40,epochs=50)\n",
        "#grid search params\n",
        "activation_function=['softmax','relu','tanh','linear']\n",
        "init=['uniform','normal','zero']\n",
        "#grid search dictionary\n",
        "param_grids=dict(activation_function=activation_function,init=init)\n",
        "\n",
        "#gridsearch cv fit\n",
        "grid=GridSearchCV(estimator=model,param_grid=param_grids,cv=KFold(),verbose=10)\n",
        "grid_result=grid.fit(x,y)"
      ],
      "metadata": {
        "id": "SJp7FENIlFpW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "975c65b3-ad07-4e7f-e1ca-fb4bb16c821d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "[CV 1/5; 1/12] START activation_function=softmax, init=uniform..................\n",
            "[CV 1/5; 1/12] END activation_function=softmax, init=uniform;, score=1.000 total time=   4.0s\n",
            "[CV 2/5; 1/12] START activation_function=softmax, init=uniform..................\n",
            "[CV 2/5; 1/12] END activation_function=softmax, init=uniform;, score=0.765 total time=   4.0s\n",
            "[CV 3/5; 1/12] START activation_function=softmax, init=uniform..................\n",
            "[CV 3/5; 1/12] END activation_function=softmax, init=uniform;, score=0.510 total time=   2.9s\n",
            "[CV 4/5; 1/12] START activation_function=softmax, init=uniform..................\n",
            "[CV 4/5; 1/12] END activation_function=softmax, init=uniform;, score=0.676 total time=   4.4s\n",
            "[CV 5/5; 1/12] START activation_function=softmax, init=uniform..................\n",
            "[CV 5/5; 1/12] END activation_function=softmax, init=uniform;, score=0.693 total time=   4.2s\n",
            "[CV 1/5; 2/12] START activation_function=softmax, init=normal...................\n",
            "[CV 1/5; 2/12] END activation_function=softmax, init=normal;, score=1.000 total time=   3.3s\n",
            "[CV 2/5; 2/12] START activation_function=softmax, init=normal...................\n",
            "[CV 2/5; 2/12] END activation_function=softmax, init=normal;, score=0.765 total time=   4.2s\n",
            "[CV 3/5; 2/12] START activation_function=softmax, init=normal...................\n",
            "[CV 3/5; 2/12] END activation_function=softmax, init=normal;, score=0.510 total time=   2.9s\n",
            "[CV 4/5; 2/12] START activation_function=softmax, init=normal...................\n",
            "[CV 4/5; 2/12] END activation_function=softmax, init=normal;, score=0.676 total time=   3.1s\n",
            "[CV 5/5; 2/12] START activation_function=softmax, init=normal...................\n",
            "[CV 5/5; 2/12] END activation_function=softmax, init=normal;, score=0.693 total time=   4.4s\n",
            "[CV 1/5; 3/12] START activation_function=softmax, init=zero.....................\n",
            "[CV 1/5; 3/12] END activation_function=softmax, init=zero;, score=1.000 total time=   4.0s\n",
            "[CV 2/5; 3/12] START activation_function=softmax, init=zero.....................\n",
            "[CV 2/5; 3/12] END activation_function=softmax, init=zero;, score=0.765 total time=   4.1s\n",
            "[CV 3/5; 3/12] START activation_function=softmax, init=zero.....................\n",
            "[CV 3/5; 3/12] END activation_function=softmax, init=zero;, score=0.510 total time=   4.5s\n",
            "[CV 4/5; 3/12] START activation_function=softmax, init=zero.....................\n",
            "[CV 4/5; 3/12] END activation_function=softmax, init=zero;, score=0.676 total time=   2.8s\n",
            "[CV 5/5; 3/12] START activation_function=softmax, init=zero.....................\n",
            "[CV 5/5; 3/12] END activation_function=softmax, init=zero;, score=0.693 total time=   3.9s\n",
            "[CV 1/5; 4/12] START activation_function=relu, init=uniform.....................\n",
            "[CV 1/5; 4/12] END activation_function=relu, init=uniform;, score=1.000 total time=   4.4s\n",
            "[CV 2/5; 4/12] START activation_function=relu, init=uniform.....................\n",
            "[CV 2/5; 4/12] END activation_function=relu, init=uniform;, score=0.765 total time=   4.1s\n",
            "[CV 3/5; 4/12] START activation_function=relu, init=uniform.....................\n",
            "[CV 3/5; 4/12] END activation_function=relu, init=uniform;, score=0.667 total time=   3.2s\n",
            "[CV 4/5; 4/12] START activation_function=relu, init=uniform.....................\n",
            "[CV 4/5; 4/12] END activation_function=relu, init=uniform;, score=0.745 total time=   4.6s\n",
            "[CV 5/5; 4/12] START activation_function=relu, init=uniform.....................\n",
            "[CV 5/5; 4/12] END activation_function=relu, init=uniform;, score=0.772 total time=   2.8s\n",
            "[CV 1/5; 5/12] START activation_function=relu, init=normal......................\n",
            "[CV 1/5; 5/12] END activation_function=relu, init=normal;, score=0.990 total time=   2.8s\n",
            "[CV 2/5; 5/12] START activation_function=relu, init=normal......................\n",
            "[CV 2/5; 5/12] END activation_function=relu, init=normal;, score=0.765 total time=   4.0s\n",
            "[CV 3/5; 5/12] START activation_function=relu, init=normal......................\n",
            "[CV 3/5; 5/12] END activation_function=relu, init=normal;, score=0.637 total time=   2.9s\n",
            "[CV 4/5; 5/12] START activation_function=relu, init=normal......................\n",
            "[CV 4/5; 5/12] END activation_function=relu, init=normal;, score=0.755 total time=   2.7s\n",
            "[CV 5/5; 5/12] START activation_function=relu, init=normal......................\n",
            "[CV 5/5; 5/12] END activation_function=relu, init=normal;, score=0.812 total time=   2.7s\n",
            "[CV 1/5; 6/12] START activation_function=relu, init=zero........................\n",
            "[CV 1/5; 6/12] END activation_function=relu, init=zero;, score=1.000 total time=   3.5s\n",
            "[CV 2/5; 6/12] START activation_function=relu, init=zero........................\n",
            "[CV 2/5; 6/12] END activation_function=relu, init=zero;, score=0.765 total time=   4.0s\n",
            "[CV 3/5; 6/12] START activation_function=relu, init=zero........................\n",
            "[CV 3/5; 6/12] END activation_function=relu, init=zero;, score=0.510 total time=   2.6s\n",
            "[CV 4/5; 6/12] START activation_function=relu, init=zero........................\n",
            "[CV 4/5; 6/12] END activation_function=relu, init=zero;, score=0.676 total time=   4.7s\n",
            "[CV 5/5; 6/12] START activation_function=relu, init=zero........................\n",
            "[CV 5/5; 6/12] END activation_function=relu, init=zero;, score=0.693 total time=   3.0s\n",
            "[CV 1/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
            "[CV 1/5; 7/12] END activation_function=tanh, init=uniform;, score=0.990 total time=   4.1s\n",
            "[CV 2/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
            "[CV 2/5; 7/12] END activation_function=tanh, init=uniform;, score=0.784 total time=   2.9s\n",
            "[CV 3/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
            "[CV 3/5; 7/12] END activation_function=tanh, init=uniform;, score=0.824 total time=   3.4s\n",
            "[CV 4/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
            "[CV 4/5; 7/12] END activation_function=tanh, init=uniform;, score=0.853 total time=   4.0s\n",
            "[CV 5/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
            "[CV 5/5; 7/12] END activation_function=tanh, init=uniform;, score=0.891 total time=   2.7s\n",
            "[CV 1/5; 8/12] START activation_function=tanh, init=normal......................\n",
            "[CV 1/5; 8/12] END activation_function=tanh, init=normal;, score=0.990 total time=   4.0s\n",
            "[CV 2/5; 8/12] START activation_function=tanh, init=normal......................\n",
            "[CV 2/5; 8/12] END activation_function=tanh, init=normal;, score=0.765 total time=   3.9s\n",
            "[CV 3/5; 8/12] START activation_function=tanh, init=normal......................\n",
            "[CV 3/5; 8/12] END activation_function=tanh, init=normal;, score=0.833 total time=   4.0s\n",
            "[CV 4/5; 8/12] START activation_function=tanh, init=normal......................\n",
            "[CV 4/5; 8/12] END activation_function=tanh, init=normal;, score=0.824 total time=   3.2s\n",
            "[CV 5/5; 8/12] START activation_function=tanh, init=normal......................\n",
            "[CV 5/5; 8/12] END activation_function=tanh, init=normal;, score=0.832 total time=   3.9s\n",
            "[CV 1/5; 9/12] START activation_function=tanh, init=zero........................\n",
            "[CV 1/5; 9/12] END activation_function=tanh, init=zero;, score=1.000 total time=   3.6s\n",
            "[CV 2/5; 9/12] START activation_function=tanh, init=zero........................\n",
            "[CV 2/5; 9/12] END activation_function=tanh, init=zero;, score=0.765 total time=   4.3s\n",
            "[CV 3/5; 9/12] START activation_function=tanh, init=zero........................\n",
            "[CV 3/5; 9/12] END activation_function=tanh, init=zero;, score=0.510 total time=   4.1s\n",
            "[CV 4/5; 9/12] START activation_function=tanh, init=zero........................\n",
            "[CV 4/5; 9/12] END activation_function=tanh, init=zero;, score=0.676 total time=   2.8s\n",
            "[CV 5/5; 9/12] START activation_function=tanh, init=zero........................\n",
            "[CV 5/5; 9/12] END activation_function=tanh, init=zero;, score=0.693 total time=   4.0s\n",
            "[CV 1/5; 10/12] START activation_function=linear, init=uniform..................\n",
            "[CV 1/5; 10/12] END activation_function=linear, init=uniform;, score=0.990 total time=   3.9s\n",
            "[CV 2/5; 10/12] START activation_function=linear, init=uniform..................\n",
            "[CV 2/5; 10/12] END activation_function=linear, init=uniform;, score=0.784 total time=   4.0s\n",
            "[CV 3/5; 10/12] START activation_function=linear, init=uniform..................\n",
            "[CV 3/5; 10/12] END activation_function=linear, init=uniform;, score=0.814 total time=   3.9s\n",
            "[CV 4/5; 10/12] START activation_function=linear, init=uniform..................\n",
            "[CV 4/5; 10/12] END activation_function=linear, init=uniform;, score=0.833 total time=   2.6s\n",
            "[CV 5/5; 10/12] START activation_function=linear, init=uniform..................\n",
            "[CV 5/5; 10/12] END activation_function=linear, init=uniform;, score=0.842 total time=   2.7s\n",
            "[CV 1/5; 11/12] START activation_function=linear, init=normal...................\n",
            "[CV 1/5; 11/12] END activation_function=linear, init=normal;, score=0.990 total time=   2.6s\n",
            "[CV 2/5; 11/12] START activation_function=linear, init=normal...................\n",
            "[CV 2/5; 11/12] END activation_function=linear, init=normal;, score=0.775 total time=   3.2s\n",
            "[CV 3/5; 11/12] START activation_function=linear, init=normal...................\n",
            "[CV 3/5; 11/12] END activation_function=linear, init=normal;, score=0.814 total time=   2.6s\n",
            "[CV 4/5; 11/12] START activation_function=linear, init=normal...................\n",
            "[CV 4/5; 11/12] END activation_function=linear, init=normal;, score=0.824 total time=   3.5s\n",
            "[CV 5/5; 11/12] START activation_function=linear, init=normal...................\n",
            "[CV 5/5; 11/12] END activation_function=linear, init=normal;, score=0.851 total time=   2.9s\n",
            "[CV 1/5; 12/12] START activation_function=linear, init=zero.....................\n",
            "[CV 1/5; 12/12] END activation_function=linear, init=zero;, score=1.000 total time=   4.2s\n",
            "[CV 2/5; 12/12] START activation_function=linear, init=zero.....................\n",
            "[CV 2/5; 12/12] END activation_function=linear, init=zero;, score=0.765 total time=   2.8s\n",
            "[CV 3/5; 12/12] START activation_function=linear, init=zero.....................\n",
            "[CV 3/5; 12/12] END activation_function=linear, init=zero;, score=0.510 total time=   4.0s\n",
            "[CV 4/5; 12/12] START activation_function=linear, init=zero.....................\n",
            "[CV 4/5; 12/12] END activation_function=linear, init=zero;, score=0.676 total time=   4.0s\n",
            "[CV 5/5; 12/12] START activation_function=linear, init=zero.....................\n",
            "[CV 5/5; 12/12] END activation_function=linear, init=zero;, score=0.693 total time=   2.6s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarizin results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "metadata": {
        "id": "jHhcTz23lFl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e22eb14-defd-4626-916c-3850e3992fdb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best : 0.8684138894081116, using {'activation_function': 'tanh', 'init': 'uniform'}\n",
            "0.728809940814972,0.1592563941055272 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
            "0.728809940814972,0.1592563941055272 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
            "0.728809940814972,0.1592563941055272 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
            "0.7897495746612548,0.11160722683257511 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
            "0.7917879939079284,0.11466821034943685 with: {'activation_function': 'relu', 'init': 'normal'}\n",
            "0.728809940814972,0.1592563941055272 with: {'activation_function': 'relu', 'init': 'zero'}\n",
            "0.8684138894081116,0.07024516366215812 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
            "0.8486895680427551,0.07514706482859035 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
            "0.728809940814972,0.1592563941055272 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
            "0.8526305437088013,0.07155342736788599 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
            "0.850689172744751,0.07398657731959539 with: {'activation_function': 'linear', 'init': 'normal'}\n",
            "0.728809940814972,0.1592563941055272 with: {'activation_function': 'linear', 'init': 'zero'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning of Hyperparameter :-Number of Neurons in activation layer"
      ],
      "metadata": {
        "id": "7kq9NIJalfYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model def\n",
        "def create_model(neuron1,neuron2):\n",
        "  model=Sequential()\n",
        "  model.add(Dense(neuron1,input_dim=30,kernel_initializer='uniform',activation='linear'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(neuron2,input_dim=neuron1,kernel_initializer='uniform',activation='linear'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  adam=Adam(learning_rate=0.001)\n",
        "  model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "#model creation\n",
        "model=KerasClassifier(build_fn=create_model,verbose=0,batch_size=40,epochs=50)\n",
        "#grid search params\n",
        "neuron1=[4,8,16]\n",
        "neuron2=[2,4,8]\n",
        "#grid search dictionary\n",
        "param_grids=dict(neuron1=neuron1,neuron2=neuron2)\n",
        "\n",
        "#gridsearch cv fit\n",
        "grid=GridSearchCV(estimator=model,param_grid=param_grids,cv=KFold(),verbose=10)\n",
        "grid_result=grid.fit(x,y)"
      ],
      "metadata": {
        "id": "7eB-km9IlFiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "137b8da1-d349-47ae-b1e7-6a2ee0d566cf"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV 1/5; 1/9] START neuron1=4, neuron2=2........................................\n",
            "[CV 1/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.990 total time=   4.0s\n",
            "[CV 2/5; 1/9] START neuron1=4, neuron2=2........................................\n",
            "[CV 2/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.765 total time=   3.9s\n",
            "[CV 3/5; 1/9] START neuron1=4, neuron2=2........................................\n",
            "[CV 3/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.696 total time=   2.9s\n",
            "[CV 4/5; 1/9] START neuron1=4, neuron2=2........................................\n",
            "[CV 4/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.716 total time=   3.0s\n",
            "[CV 5/5; 1/9] START neuron1=4, neuron2=2........................................\n",
            "[CV 5/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.733 total time=   2.6s\n",
            "[CV 1/5; 2/9] START neuron1=4, neuron2=4........................................\n",
            "[CV 1/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.990 total time=   2.6s\n",
            "[CV 2/5; 2/9] START neuron1=4, neuron2=4........................................\n",
            "[CV 2/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.765 total time=   5.2s\n",
            "[CV 3/5; 2/9] START neuron1=4, neuron2=4........................................\n",
            "[CV 3/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.696 total time=   4.2s\n",
            "[CV 4/5; 2/9] START neuron1=4, neuron2=4........................................\n",
            "[CV 4/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.735 total time=   2.9s\n",
            "[CV 5/5; 2/9] START neuron1=4, neuron2=4........................................\n",
            "[CV 5/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.772 total time=   4.0s\n",
            "[CV 1/5; 3/9] START neuron1=4, neuron2=8........................................\n",
            "[CV 1/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.990 total time=   4.0s\n",
            "[CV 2/5; 3/9] START neuron1=4, neuron2=8........................................\n",
            "[CV 2/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.765 total time=   2.8s\n",
            "[CV 3/5; 3/9] START neuron1=4, neuron2=8........................................\n",
            "[CV 3/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.765 total time=   2.7s\n",
            "[CV 4/5; 3/9] START neuron1=4, neuron2=8........................................\n",
            "[CV 4/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.784 total time=   4.5s\n",
            "[CV 5/5; 3/9] START neuron1=4, neuron2=8........................................\n",
            "[CV 5/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.792 total time=   3.9s\n",
            "[CV 1/5; 4/9] START neuron1=8, neuron2=2........................................\n",
            "[CV 1/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.990 total time=   2.5s\n",
            "[CV 2/5; 4/9] START neuron1=8, neuron2=2........................................\n",
            "[CV 2/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.765 total time=   3.2s\n",
            "[CV 3/5; 4/9] START neuron1=8, neuron2=2........................................\n",
            "[CV 3/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.745 total time=   2.6s\n",
            "[CV 4/5; 4/9] START neuron1=8, neuron2=2........................................\n",
            "[CV 4/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.745 total time=   4.8s\n",
            "[CV 5/5; 4/9] START neuron1=8, neuron2=2........................................\n",
            "[CV 5/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.772 total time=   4.3s\n",
            "[CV 1/5; 5/9] START neuron1=8, neuron2=4........................................\n",
            "[CV 1/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.990 total time=   4.2s\n",
            "[CV 2/5; 5/9] START neuron1=8, neuron2=4........................................\n",
            "[CV 2/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.765 total time=   2.9s\n",
            "[CV 3/5; 5/9] START neuron1=8, neuron2=4........................................\n",
            "[CV 3/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.784 total time=   3.1s\n",
            "[CV 4/5; 5/9] START neuron1=8, neuron2=4........................................\n",
            "[CV 4/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.804 total time=   3.0s\n",
            "[CV 5/5; 5/9] START neuron1=8, neuron2=4........................................\n",
            "[CV 5/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.832 total time=   2.7s\n",
            "[CV 1/5; 6/9] START neuron1=8, neuron2=8........................................\n",
            "[CV 1/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.990 total time=   4.0s\n",
            "[CV 2/5; 6/9] START neuron1=8, neuron2=8........................................\n",
            "[CV 2/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.775 total time=   4.0s\n",
            "[CV 3/5; 6/9] START neuron1=8, neuron2=8........................................\n",
            "[CV 3/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.824 total time=   2.7s\n",
            "[CV 4/5; 6/9] START neuron1=8, neuron2=8........................................\n",
            "[CV 4/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.824 total time=   4.0s\n",
            "[CV 5/5; 6/9] START neuron1=8, neuron2=8........................................\n",
            "[CV 5/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.861 total time=   2.9s\n",
            "[CV 1/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
            "[CV 1/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.990 total time=   2.8s\n",
            "[CV 2/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
            "[CV 2/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.765 total time=   3.6s\n",
            "[CV 3/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
            "[CV 3/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.735 total time=   4.3s\n",
            "[CV 4/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
            "[CV 4/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.804 total time=   4.7s\n",
            "[CV 5/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
            "[CV 5/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.822 total time=   2.8s\n",
            "[CV 1/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
            "[CV 1/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.990 total time=   2.7s\n",
            "[CV 2/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
            "[CV 2/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.775 total time=   3.5s\n",
            "[CV 3/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
            "[CV 3/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.824 total time=   4.0s\n",
            "[CV 4/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
            "[CV 4/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.833 total time=   4.0s\n",
            "[CV 5/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
            "[CV 5/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.881 total time=   2.9s\n",
            "[CV 1/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
            "[CV 1/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.990 total time=   2.9s\n",
            "[CV 2/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
            "[CV 2/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.794 total time=   2.7s\n",
            "[CV 3/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
            "[CV 3/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.833 total time=   2.6s\n",
            "[CV 4/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
            "[CV 4/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.873 total time=   2.5s\n",
            "[CV 5/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
            "[CV 5/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.881 total time=   6.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarizing the results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "metadata": {
        "id": "56zwOpjoljF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed005ef1-e670-46e3-ba29-fb715347a123"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best : 0.8742768168449402, using {'neuron1': 16, 'neuron2': 8}\n",
            "0.7798679828643799,0.10755008868130986 with: {'neuron1': 4, 'neuron2': 2}\n",
            "0.7917103409767151,0.10279272170640003 with: {'neuron1': 4, 'neuron2': 4}\n",
            "0.8192001581192017,0.08617592702471132 with: {'neuron1': 4, 'neuron2': 8}\n",
            "0.8034750580787658,0.09397534745627452 with: {'neuron1': 8, 'neuron2': 2}\n",
            "0.8349640846252442,0.0807131153798453 with: {'neuron1': 8, 'neuron2': 4}\n",
            "0.8546301603317261,0.07318133528588279 with: {'neuron1': 8, 'neuron2': 8}\n",
            "0.8231799602508545,0.0887810260405273 with: {'neuron1': 16, 'neuron2': 2}\n",
            "0.8605513334274292,0.07314125836265385 with: {'neuron1': 16, 'neuron2': 4}\n",
            "0.8742768168449402,0.0657113161238888 with: {'neuron1': 16, 'neuron2': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training model with optimum values of Hyperparameters"
      ],
      "metadata": {
        "id": "MAMeCcZylo-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python program to define a function to compute accuracy score of model's predicted class  \n",
        "  \n",
        "# Defining a function which takes true values of the sample and values predicted by the model  \n",
        "def compute_accuracy(Y_true, Y_pred):  \n",
        "    correctly_predicted = 0  \n",
        "    # iterating over every label and checking it with the true sample  \n",
        "    for true_label, predicted in zip(Y_true, Y_pred):  \n",
        "        if true_label == predicted:  \n",
        "            correctly_predicted += 1  \n",
        "    # computing the accuracy score  \n",
        "    accuracy_score = correctly_predicted / len(Y_true)  \n",
        "    return accuracy_score  "
      ],
      "metadata": {
        "id": "H0QsFeiUkhIR"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "#model def\n",
        "def create_model():\n",
        "  model=Sequential()\n",
        "  model.add(Dense(16,input_dim=30,kernel_initializer='uniform',activation='linear'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(4,input_dim=16,kernel_initializer='uniform',activation='linear'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  adam=Adam(learning_rate=0.01)\n",
        "  model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "#model creation\n",
        "model=KerasClassifier(build_fn=create_model,verbose=0,batch_size=20,epochs=50)\n",
        "#model fit\n",
        "model.fit(x,y)\n",
        "#prediction on train \n",
        "y_pred=model.predict(x)\n",
        "#printing mertics\n",
        "compute_accuracy(y,y_pred)"
      ],
      "metadata": {
        "id": "wGKgUieultY4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c6fc7f-4439-41ba-d022-cb26ac324a9d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9705304518664047"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final plot with accuracy of train and test\n",
        "history = model.fit(x,y,validation_split = 0.3, epochs=50, batch_size=20)\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sng-gcAvltTb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "outputId": "0bb8f006-e29c-445a-e4b4-21642dfcce74"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Regressor"
      ],
      "metadata": {
        "id": "_a686vRRl3B4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(30,30))\n",
        "mlp.fit(x_train,y_train)\n",
        "pred_train=mlp.predict(x_train)\n",
        "pred_test=mlp.predict(x_test)"
      ],
      "metadata": {
        "id": "tqP2_kQHl7sW"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "rs1=r2_score(y_train,pred_train)\n",
        "mse1=mean_squared_error(y_train,pred_train)\n",
        "rs1,mse1"
      ],
      "metadata": {
        "id": "HNBX6DFel7lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "030bb64b-7add-4d17-ec7d-696786c169e2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8408248458579876, 0.15868514177871332)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rs2=r2_score(y_test,pred_test)\n",
        "mse2=mean_squared_error(y_train,pred_train)\n",
        "rs2,mse2"
      ],
      "metadata": {
        "id": "2LXmUf7sl7hy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eba1b2e2-7f5e-4634-b1c6-7ebbb034aca5"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.17814418285565525, 0.15868514177871332)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras \n",
        "!pip install tensorflow\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "6srbh5Bdl7Wm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d36ca7-3ad5-4e1f-efd2-8c315f8ec660"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(15,input_dim=30,activation=\"relu\"))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"mean_squared_error\"])"
      ],
      "metadata": {
        "id": "o39RO61xltMR"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(x,y,validation_split=0.33,epochs=250,batch_size=10)\n",
        "scores=model.evaluate(x,y)\n",
        "print(\"%s: %.2f%%\"%(model.metrics_names[1],scores[1]*100))\n",
        "history.history.keys()"
      ],
      "metadata": {
        "id": "hy3odHqBkBza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d19f3f31-f995-4668-edbe-c8d07c64bf81"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "35/35 [==============================] - 1s 12ms/step - loss: 1.0442 - mean_squared_error: 1.2670 - val_loss: 1.1655 - val_mean_squared_error: 1.6884\n",
            "Epoch 2/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.8062 - mean_squared_error: 1.1712 - val_loss: 0.9719 - val_mean_squared_error: 1.6037\n",
            "Epoch 3/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.6219 - mean_squared_error: 1.0891 - val_loss: 0.8246 - val_mean_squared_error: 1.5338\n",
            "Epoch 4/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4755 - mean_squared_error: 1.0211 - val_loss: 0.6877 - val_mean_squared_error: 1.4684\n",
            "Epoch 5/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3671 - mean_squared_error: 0.9771 - val_loss: 0.5896 - val_mean_squared_error: 1.4234\n",
            "Epoch 6/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2779 - mean_squared_error: 0.9466 - val_loss: 0.5014 - val_mean_squared_error: 1.3851\n",
            "Epoch 7/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.1990 - mean_squared_error: 0.9255 - val_loss: 0.4314 - val_mean_squared_error: 1.3571\n",
            "Epoch 8/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1239 - mean_squared_error: 0.9090 - val_loss: 0.3588 - val_mean_squared_error: 1.3330\n",
            "Epoch 9/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.0600 - mean_squared_error: 0.8991 - val_loss: 0.2900 - val_mean_squared_error: 1.3114\n",
            "Epoch 10/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 6.3591e-04 - mean_squared_error: 0.8929 - val_loss: 0.2439 - val_mean_squared_error: 1.2996\n",
            "Epoch 11/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -0.0541 - mean_squared_error: 0.8882 - val_loss: 0.1762 - val_mean_squared_error: 1.2826\n",
            "Epoch 12/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -0.1115 - mean_squared_error: 0.8838 - val_loss: 0.1171 - val_mean_squared_error: 1.2695\n",
            "Epoch 13/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -0.1728 - mean_squared_error: 0.8811 - val_loss: 0.0503 - val_mean_squared_error: 1.2562\n",
            "Epoch 14/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -0.2278 - mean_squared_error: 0.8784 - val_loss: 0.0042 - val_mean_squared_error: 1.2482\n",
            "Epoch 15/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -0.2826 - mean_squared_error: 0.8767 - val_loss: -0.0402 - val_mean_squared_error: 1.2423\n",
            "Epoch 16/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -0.3425 - mean_squared_error: 0.8761 - val_loss: -0.1068 - val_mean_squared_error: 1.2312\n",
            "Epoch 17/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -0.4013 - mean_squared_error: 0.8743 - val_loss: -0.1482 - val_mean_squared_error: 1.2275\n",
            "Epoch 18/250\n",
            "35/35 [==============================] - 0s 7ms/step - loss: -0.4702 - mean_squared_error: 0.8741 - val_loss: -0.2101 - val_mean_squared_error: 1.2218\n",
            "Epoch 19/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -0.5382 - mean_squared_error: 0.8749 - val_loss: -0.2800 - val_mean_squared_error: 1.2156\n",
            "Epoch 20/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -0.6136 - mean_squared_error: 0.8746 - val_loss: -0.3507 - val_mean_squared_error: 1.2110\n",
            "Epoch 21/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -0.6990 - mean_squared_error: 0.8749 - val_loss: -0.4020 - val_mean_squared_error: 1.2078\n",
            "Epoch 22/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -0.7719 - mean_squared_error: 0.8754 - val_loss: -0.4373 - val_mean_squared_error: 1.2060\n",
            "Epoch 23/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -0.8367 - mean_squared_error: 0.8773 - val_loss: -0.5149 - val_mean_squared_error: 1.2001\n",
            "Epoch 24/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -0.9070 - mean_squared_error: 0.8757 - val_loss: -0.5648 - val_mean_squared_error: 1.1993\n",
            "Epoch 25/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -0.9740 - mean_squared_error: 0.8750 - val_loss: -0.6143 - val_mean_squared_error: 1.1976\n",
            "Epoch 26/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -1.0502 - mean_squared_error: 0.8748 - val_loss: -0.6583 - val_mean_squared_error: 1.1965\n",
            "Epoch 27/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -1.1255 - mean_squared_error: 0.8762 - val_loss: -0.7130 - val_mean_squared_error: 1.1939\n",
            "Epoch 28/250\n",
            "35/35 [==============================] - 0s 3ms/step - loss: -1.2026 - mean_squared_error: 0.8752 - val_loss: -0.7738 - val_mean_squared_error: 1.1912\n",
            "Epoch 29/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -1.2856 - mean_squared_error: 0.8758 - val_loss: -0.8330 - val_mean_squared_error: 1.1865\n",
            "Epoch 30/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -1.3643 - mean_squared_error: 0.8757 - val_loss: -0.9021 - val_mean_squared_error: 1.1843\n",
            "Epoch 31/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -1.4555 - mean_squared_error: 0.8752 - val_loss: -0.9525 - val_mean_squared_error: 1.1837\n",
            "Epoch 32/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -1.5393 - mean_squared_error: 0.8744 - val_loss: -1.0121 - val_mean_squared_error: 1.1848\n",
            "Epoch 33/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -1.6367 - mean_squared_error: 0.8738 - val_loss: -1.0877 - val_mean_squared_error: 1.1827\n",
            "Epoch 34/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -1.7313 - mean_squared_error: 0.8748 - val_loss: -1.1558 - val_mean_squared_error: 1.1835\n",
            "Epoch 35/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -1.8389 - mean_squared_error: 0.8732 - val_loss: -1.2236 - val_mean_squared_error: 1.1826\n",
            "Epoch 36/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -1.9380 - mean_squared_error: 0.8716 - val_loss: -1.2916 - val_mean_squared_error: 1.1816\n",
            "Epoch 37/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -2.0457 - mean_squared_error: 0.8705 - val_loss: -1.3527 - val_mean_squared_error: 1.1804\n",
            "Epoch 38/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -2.1546 - mean_squared_error: 0.8707 - val_loss: -1.4445 - val_mean_squared_error: 1.1802\n",
            "Epoch 39/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -2.2834 - mean_squared_error: 0.8710 - val_loss: -1.5075 - val_mean_squared_error: 1.1796\n",
            "Epoch 40/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -2.3977 - mean_squared_error: 0.8699 - val_loss: -1.5878 - val_mean_squared_error: 1.1791\n",
            "Epoch 41/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -2.5208 - mean_squared_error: 0.8681 - val_loss: -1.6749 - val_mean_squared_error: 1.1799\n",
            "Epoch 42/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -2.6496 - mean_squared_error: 0.8675 - val_loss: -1.7575 - val_mean_squared_error: 1.1791\n",
            "Epoch 43/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -2.7964 - mean_squared_error: 0.8656 - val_loss: -1.8253 - val_mean_squared_error: 1.1777\n",
            "Epoch 44/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -2.9308 - mean_squared_error: 0.8643 - val_loss: -1.9346 - val_mean_squared_error: 1.1761\n",
            "Epoch 45/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -3.0819 - mean_squared_error: 0.8638 - val_loss: -2.0236 - val_mean_squared_error: 1.1762\n",
            "Epoch 46/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -3.2228 - mean_squared_error: 0.8631 - val_loss: -2.1121 - val_mean_squared_error: 1.1774\n",
            "Epoch 47/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -3.3822 - mean_squared_error: 0.8612 - val_loss: -2.2168 - val_mean_squared_error: 1.1754\n",
            "Epoch 48/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -3.5360 - mean_squared_error: 0.8606 - val_loss: -2.3154 - val_mean_squared_error: 1.1771\n",
            "Epoch 49/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -3.6987 - mean_squared_error: 0.8583 - val_loss: -2.4319 - val_mean_squared_error: 1.1764\n",
            "Epoch 50/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -3.8573 - mean_squared_error: 0.8583 - val_loss: -2.6208 - val_mean_squared_error: 1.1773\n",
            "Epoch 51/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -4.0581 - mean_squared_error: 0.8608 - val_loss: -2.7543 - val_mean_squared_error: 1.1814\n",
            "Epoch 52/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -4.2421 - mean_squared_error: 0.8600 - val_loss: -2.8507 - val_mean_squared_error: 1.1805\n",
            "Epoch 53/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -4.4187 - mean_squared_error: 0.8595 - val_loss: -2.9712 - val_mean_squared_error: 1.1780\n",
            "Epoch 54/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -4.5915 - mean_squared_error: 0.8575 - val_loss: -3.1025 - val_mean_squared_error: 1.1777\n",
            "Epoch 55/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -4.8074 - mean_squared_error: 0.8567 - val_loss: -3.2177 - val_mean_squared_error: 1.1781\n",
            "Epoch 56/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -5.0023 - mean_squared_error: 0.8567 - val_loss: -3.3566 - val_mean_squared_error: 1.1810\n",
            "Epoch 57/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -5.1997 - mean_squared_error: 0.8544 - val_loss: -3.4902 - val_mean_squared_error: 1.1794\n",
            "Epoch 58/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -5.4229 - mean_squared_error: 0.8553 - val_loss: -3.6833 - val_mean_squared_error: 1.1804\n",
            "Epoch 59/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -5.6239 - mean_squared_error: 0.8566 - val_loss: -3.8412 - val_mean_squared_error: 1.1803\n",
            "Epoch 60/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -5.8389 - mean_squared_error: 0.8539 - val_loss: -3.9324 - val_mean_squared_error: 1.1744\n",
            "Epoch 61/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -6.0486 - mean_squared_error: 0.8525 - val_loss: -4.0588 - val_mean_squared_error: 1.1763\n",
            "Epoch 62/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -6.2706 - mean_squared_error: 0.8521 - val_loss: -4.2134 - val_mean_squared_error: 1.1751\n",
            "Epoch 63/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -6.5245 - mean_squared_error: 0.8537 - val_loss: -4.3592 - val_mean_squared_error: 1.1737\n",
            "Epoch 64/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -6.7884 - mean_squared_error: 0.8522 - val_loss: -4.4982 - val_mean_squared_error: 1.1754\n",
            "Epoch 65/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -6.9937 - mean_squared_error: 0.8519 - val_loss: -4.6479 - val_mean_squared_error: 1.1771\n",
            "Epoch 66/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -7.2025 - mean_squared_error: 0.8495 - val_loss: -4.7871 - val_mean_squared_error: 1.1767\n",
            "Epoch 67/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -7.4439 - mean_squared_error: 0.8510 - val_loss: -4.9546 - val_mean_squared_error: 1.1810\n",
            "Epoch 68/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -7.6673 - mean_squared_error: 0.8512 - val_loss: -5.1339 - val_mean_squared_error: 1.1823\n",
            "Epoch 69/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -7.8915 - mean_squared_error: 0.8502 - val_loss: -5.2842 - val_mean_squared_error: 1.1832\n",
            "Epoch 70/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -8.2070 - mean_squared_error: 0.8496 - val_loss: -5.5083 - val_mean_squared_error: 1.1869\n",
            "Epoch 71/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -8.4605 - mean_squared_error: 0.8492 - val_loss: -5.6814 - val_mean_squared_error: 1.1911\n",
            "Epoch 72/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -8.7122 - mean_squared_error: 0.8522 - val_loss: -5.8684 - val_mean_squared_error: 1.1995\n",
            "Epoch 73/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -8.9579 - mean_squared_error: 0.8525 - val_loss: -6.0247 - val_mean_squared_error: 1.1968\n",
            "Epoch 74/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -9.2012 - mean_squared_error: 0.8508 - val_loss: -6.2127 - val_mean_squared_error: 1.1941\n",
            "Epoch 75/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -9.4397 - mean_squared_error: 0.8516 - val_loss: -6.4107 - val_mean_squared_error: 1.2010\n",
            "Epoch 76/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -9.7258 - mean_squared_error: 0.8516 - val_loss: -6.5784 - val_mean_squared_error: 1.2013\n",
            "Epoch 77/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -9.9804 - mean_squared_error: 0.8497 - val_loss: -6.7272 - val_mean_squared_error: 1.1986\n",
            "Epoch 78/250\n",
            "35/35 [==============================] - 0s 7ms/step - loss: -10.2468 - mean_squared_error: 0.8485 - val_loss: -6.9065 - val_mean_squared_error: 1.2015\n",
            "Epoch 79/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -10.5115 - mean_squared_error: 0.8483 - val_loss: -7.0575 - val_mean_squared_error: 1.1987\n",
            "Epoch 80/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -10.7836 - mean_squared_error: 0.8484 - val_loss: -7.2131 - val_mean_squared_error: 1.1997\n",
            "Epoch 81/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -11.0734 - mean_squared_error: 0.8486 - val_loss: -7.4396 - val_mean_squared_error: 1.2018\n",
            "Epoch 82/250\n",
            "35/35 [==============================] - 0s 7ms/step - loss: -11.3570 - mean_squared_error: 0.8472 - val_loss: -7.6616 - val_mean_squared_error: 1.2079\n",
            "Epoch 83/250\n",
            "35/35 [==============================] - 0s 7ms/step - loss: -11.6472 - mean_squared_error: 0.8508 - val_loss: -7.8672 - val_mean_squared_error: 1.2023\n",
            "Epoch 84/250\n",
            "35/35 [==============================] - 0s 7ms/step - loss: -11.9400 - mean_squared_error: 0.8500 - val_loss: -8.0365 - val_mean_squared_error: 1.2021\n",
            "Epoch 85/250\n",
            "35/35 [==============================] - 0s 7ms/step - loss: -12.2120 - mean_squared_error: 0.8472 - val_loss: -8.2143 - val_mean_squared_error: 1.1969\n",
            "Epoch 86/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -12.5111 - mean_squared_error: 0.8507 - val_loss: -8.4309 - val_mean_squared_error: 1.2020\n",
            "Epoch 87/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -12.8307 - mean_squared_error: 0.8489 - val_loss: -8.6344 - val_mean_squared_error: 1.2020\n",
            "Epoch 88/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -13.1169 - mean_squared_error: 0.8483 - val_loss: -8.8726 - val_mean_squared_error: 1.2106\n",
            "Epoch 89/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -13.4496 - mean_squared_error: 0.8495 - val_loss: -9.1540 - val_mean_squared_error: 1.2119\n",
            "Epoch 90/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -13.7672 - mean_squared_error: 0.8530 - val_loss: -9.4549 - val_mean_squared_error: 1.2183\n",
            "Epoch 91/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -14.0650 - mean_squared_error: 0.8574 - val_loss: -9.7648 - val_mean_squared_error: 1.2209\n",
            "Epoch 92/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -14.3948 - mean_squared_error: 0.8578 - val_loss: -9.9493 - val_mean_squared_error: 1.2210\n",
            "Epoch 93/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -14.7018 - mean_squared_error: 0.8588 - val_loss: -10.1625 - val_mean_squared_error: 1.2203\n",
            "Epoch 94/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -15.1061 - mean_squared_error: 0.8564 - val_loss: -10.3716 - val_mean_squared_error: 1.2137\n",
            "Epoch 95/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -15.4420 - mean_squared_error: 0.8572 - val_loss: -10.6214 - val_mean_squared_error: 1.2158\n",
            "Epoch 96/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -15.7339 - mean_squared_error: 0.8571 - val_loss: -10.8209 - val_mean_squared_error: 1.2149\n",
            "Epoch 97/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -16.0578 - mean_squared_error: 0.8559 - val_loss: -11.0397 - val_mean_squared_error: 1.2190\n",
            "Epoch 98/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -16.3825 - mean_squared_error: 0.8549 - val_loss: -11.2178 - val_mean_squared_error: 1.2184\n",
            "Epoch 99/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -16.6857 - mean_squared_error: 0.8490 - val_loss: -11.3672 - val_mean_squared_error: 1.2149\n",
            "Epoch 100/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -17.0055 - mean_squared_error: 0.8504 - val_loss: -11.6226 - val_mean_squared_error: 1.2114\n",
            "Epoch 101/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -17.3662 - mean_squared_error: 0.8512 - val_loss: -11.8897 - val_mean_squared_error: 1.2212\n",
            "Epoch 102/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -17.7116 - mean_squared_error: 0.8535 - val_loss: -12.1805 - val_mean_squared_error: 1.2286\n",
            "Epoch 103/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -18.0359 - mean_squared_error: 0.8580 - val_loss: -12.4620 - val_mean_squared_error: 1.2313\n",
            "Epoch 104/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -18.3707 - mean_squared_error: 0.8569 - val_loss: -12.7059 - val_mean_squared_error: 1.2290\n",
            "Epoch 105/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -18.7244 - mean_squared_error: 0.8564 - val_loss: -12.9819 - val_mean_squared_error: 1.2264\n",
            "Epoch 106/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -19.0750 - mean_squared_error: 0.8561 - val_loss: -13.2004 - val_mean_squared_error: 1.2209\n",
            "Epoch 107/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -19.4323 - mean_squared_error: 0.8555 - val_loss: -13.4082 - val_mean_squared_error: 1.2182\n",
            "Epoch 108/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -19.7747 - mean_squared_error: 0.8562 - val_loss: -13.7004 - val_mean_squared_error: 1.2166\n",
            "Epoch 109/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -20.1865 - mean_squared_error: 0.8588 - val_loss: -14.0787 - val_mean_squared_error: 1.2211\n",
            "Epoch 110/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -20.5707 - mean_squared_error: 0.8552 - val_loss: -14.3174 - val_mean_squared_error: 1.2197\n",
            "Epoch 111/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -20.9074 - mean_squared_error: 0.8539 - val_loss: -14.5839 - val_mean_squared_error: 1.2176\n",
            "Epoch 112/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -21.3027 - mean_squared_error: 0.8542 - val_loss: -14.7989 - val_mean_squared_error: 1.2206\n",
            "Epoch 113/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -21.6430 - mean_squared_error: 0.8539 - val_loss: -15.0312 - val_mean_squared_error: 1.2168\n",
            "Epoch 114/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -22.0239 - mean_squared_error: 0.8540 - val_loss: -15.2449 - val_mean_squared_error: 1.2145\n",
            "Epoch 115/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -22.3975 - mean_squared_error: 0.8539 - val_loss: -15.4970 - val_mean_squared_error: 1.2145\n",
            "Epoch 116/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -22.8114 - mean_squared_error: 0.8559 - val_loss: -15.7646 - val_mean_squared_error: 1.2119\n",
            "Epoch 117/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -23.1885 - mean_squared_error: 0.8593 - val_loss: -16.0387 - val_mean_squared_error: 1.2111\n",
            "Epoch 118/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -23.5642 - mean_squared_error: 0.8551 - val_loss: -16.3486 - val_mean_squared_error: 1.2139\n",
            "Epoch 119/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -23.9800 - mean_squared_error: 0.8559 - val_loss: -16.6451 - val_mean_squared_error: 1.2097\n",
            "Epoch 120/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -24.3638 - mean_squared_error: 0.8595 - val_loss: -16.9517 - val_mean_squared_error: 1.2149\n",
            "Epoch 121/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -24.7676 - mean_squared_error: 0.8551 - val_loss: -17.2129 - val_mean_squared_error: 1.2114\n",
            "Epoch 122/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -25.1811 - mean_squared_error: 0.8535 - val_loss: -17.4949 - val_mean_squared_error: 1.2131\n",
            "Epoch 123/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -25.5708 - mean_squared_error: 0.8549 - val_loss: -17.8026 - val_mean_squared_error: 1.2220\n",
            "Epoch 124/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -25.9577 - mean_squared_error: 0.8564 - val_loss: -18.0676 - val_mean_squared_error: 1.2191\n",
            "Epoch 125/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -26.3911 - mean_squared_error: 0.8572 - val_loss: -18.4052 - val_mean_squared_error: 1.2162\n",
            "Epoch 126/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -26.8118 - mean_squared_error: 0.8547 - val_loss: -18.6448 - val_mean_squared_error: 1.2113\n",
            "Epoch 127/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -27.1907 - mean_squared_error: 0.8548 - val_loss: -18.9543 - val_mean_squared_error: 1.2099\n",
            "Epoch 128/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -27.6282 - mean_squared_error: 0.8547 - val_loss: -19.2412 - val_mean_squared_error: 1.2084\n",
            "Epoch 129/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -28.0302 - mean_squared_error: 0.8561 - val_loss: -19.5546 - val_mean_squared_error: 1.2074\n",
            "Epoch 130/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -28.4891 - mean_squared_error: 0.8581 - val_loss: -19.8304 - val_mean_squared_error: 1.2065\n",
            "Epoch 131/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -28.9150 - mean_squared_error: 0.8538 - val_loss: -20.1096 - val_mean_squared_error: 1.2045\n",
            "Epoch 132/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -29.3279 - mean_squared_error: 0.8514 - val_loss: -20.4169 - val_mean_squared_error: 1.2065\n",
            "Epoch 133/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -29.7711 - mean_squared_error: 0.8553 - val_loss: -20.7209 - val_mean_squared_error: 1.2023\n",
            "Epoch 134/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -30.2250 - mean_squared_error: 0.8547 - val_loss: -21.0774 - val_mean_squared_error: 1.2067\n",
            "Epoch 135/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -30.6473 - mean_squared_error: 0.8595 - val_loss: -21.5045 - val_mean_squared_error: 1.2113\n",
            "Epoch 136/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -31.1125 - mean_squared_error: 0.8580 - val_loss: -21.7686 - val_mean_squared_error: 1.2058\n",
            "Epoch 137/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -31.5512 - mean_squared_error: 0.8570 - val_loss: -22.0818 - val_mean_squared_error: 1.2056\n",
            "Epoch 138/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -31.9863 - mean_squared_error: 0.8641 - val_loss: -22.3781 - val_mean_squared_error: 1.2057\n",
            "Epoch 139/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -32.4513 - mean_squared_error: 0.8604 - val_loss: -22.6853 - val_mean_squared_error: 1.2047\n",
            "Epoch 140/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -32.9236 - mean_squared_error: 0.8641 - val_loss: -23.1197 - val_mean_squared_error: 1.2058\n",
            "Epoch 141/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -33.4024 - mean_squared_error: 0.8685 - val_loss: -23.5312 - val_mean_squared_error: 1.2068\n",
            "Epoch 142/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -33.8244 - mean_squared_error: 0.8670 - val_loss: -23.8047 - val_mean_squared_error: 1.2045\n",
            "Epoch 143/250\n",
            "35/35 [==============================] - 0s 7ms/step - loss: -34.3012 - mean_squared_error: 0.8654 - val_loss: -24.1357 - val_mean_squared_error: 1.2059\n",
            "Epoch 144/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -34.8672 - mean_squared_error: 0.8649 - val_loss: -24.4595 - val_mean_squared_error: 1.1992\n",
            "Epoch 145/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -35.3559 - mean_squared_error: 0.8653 - val_loss: -24.7383 - val_mean_squared_error: 1.1876\n",
            "Epoch 146/250\n",
            "35/35 [==============================] - 0s 7ms/step - loss: -35.8410 - mean_squared_error: 0.8660 - val_loss: -25.0723 - val_mean_squared_error: 1.1904\n",
            "Epoch 147/250\n",
            "35/35 [==============================] - 0s 7ms/step - loss: -36.3003 - mean_squared_error: 0.8642 - val_loss: -25.4248 - val_mean_squared_error: 1.2002\n",
            "Epoch 148/250\n",
            "35/35 [==============================] - 0s 8ms/step - loss: -36.7285 - mean_squared_error: 0.8636 - val_loss: -25.8460 - val_mean_squared_error: 1.2074\n",
            "Epoch 149/250\n",
            "35/35 [==============================] - 0s 7ms/step - loss: -37.2001 - mean_squared_error: 0.8626 - val_loss: -26.1415 - val_mean_squared_error: 1.2019\n",
            "Epoch 150/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -37.6897 - mean_squared_error: 0.8642 - val_loss: -26.5626 - val_mean_squared_error: 1.1980\n",
            "Epoch 151/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -38.1503 - mean_squared_error: 0.8632 - val_loss: -26.8362 - val_mean_squared_error: 1.1964\n",
            "Epoch 152/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -38.6613 - mean_squared_error: 0.8670 - val_loss: -27.2476 - val_mean_squared_error: 1.1946\n",
            "Epoch 153/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -39.1025 - mean_squared_error: 0.8657 - val_loss: -27.6115 - val_mean_squared_error: 1.1970\n",
            "Epoch 154/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -39.6071 - mean_squared_error: 0.8635 - val_loss: -27.9381 - val_mean_squared_error: 1.1906\n",
            "Epoch 155/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -40.0969 - mean_squared_error: 0.8632 - val_loss: -28.2429 - val_mean_squared_error: 1.1901\n",
            "Epoch 156/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -40.5554 - mean_squared_error: 0.8631 - val_loss: -28.5619 - val_mean_squared_error: 1.1911\n",
            "Epoch 157/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -41.0797 - mean_squared_error: 0.8602 - val_loss: -28.8575 - val_mean_squared_error: 1.1878\n",
            "Epoch 158/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -41.5675 - mean_squared_error: 0.8599 - val_loss: -29.1917 - val_mean_squared_error: 1.1882\n",
            "Epoch 159/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -42.0276 - mean_squared_error: 0.8621 - val_loss: -29.5585 - val_mean_squared_error: 1.1880\n",
            "Epoch 160/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -42.5073 - mean_squared_error: 0.8605 - val_loss: -29.9102 - val_mean_squared_error: 1.1888\n",
            "Epoch 161/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -43.0617 - mean_squared_error: 0.8634 - val_loss: -30.4408 - val_mean_squared_error: 1.1876\n",
            "Epoch 162/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -43.6018 - mean_squared_error: 0.8661 - val_loss: -30.7646 - val_mean_squared_error: 1.1871\n",
            "Epoch 163/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -44.1816 - mean_squared_error: 0.8639 - val_loss: -31.1217 - val_mean_squared_error: 1.1835\n",
            "Epoch 164/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -44.7309 - mean_squared_error: 0.8627 - val_loss: -31.4798 - val_mean_squared_error: 1.1824\n",
            "Epoch 165/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -45.2285 - mean_squared_error: 0.8623 - val_loss: -31.6900 - val_mean_squared_error: 1.1810\n",
            "Epoch 166/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -45.7236 - mean_squared_error: 0.8598 - val_loss: -32.1065 - val_mean_squared_error: 1.1832\n",
            "Epoch 167/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -46.2154 - mean_squared_error: 0.8592 - val_loss: -32.4900 - val_mean_squared_error: 1.1835\n",
            "Epoch 168/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -46.6975 - mean_squared_error: 0.8611 - val_loss: -32.8474 - val_mean_squared_error: 1.1837\n",
            "Epoch 169/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -47.1952 - mean_squared_error: 0.8599 - val_loss: -33.2175 - val_mean_squared_error: 1.1823\n",
            "Epoch 170/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -47.7118 - mean_squared_error: 0.8592 - val_loss: -33.6049 - val_mean_squared_error: 1.1822\n",
            "Epoch 171/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -48.2393 - mean_squared_error: 0.8606 - val_loss: -33.8815 - val_mean_squared_error: 1.1785\n",
            "Epoch 172/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -48.7302 - mean_squared_error: 0.8613 - val_loss: -34.3265 - val_mean_squared_error: 1.1796\n",
            "Epoch 173/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -49.2167 - mean_squared_error: 0.8601 - val_loss: -34.7063 - val_mean_squared_error: 1.1761\n",
            "Epoch 174/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -49.7841 - mean_squared_error: 0.8590 - val_loss: -35.0453 - val_mean_squared_error: 1.1784\n",
            "Epoch 175/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -50.2733 - mean_squared_error: 0.8604 - val_loss: -35.5429 - val_mean_squared_error: 1.1813\n",
            "Epoch 176/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -50.8088 - mean_squared_error: 0.8634 - val_loss: -35.9158 - val_mean_squared_error: 1.1794\n",
            "Epoch 177/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -51.3278 - mean_squared_error: 0.8609 - val_loss: -36.3117 - val_mean_squared_error: 1.1792\n",
            "Epoch 178/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -51.8888 - mean_squared_error: 0.8607 - val_loss: -36.6582 - val_mean_squared_error: 1.1766\n",
            "Epoch 179/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -52.4013 - mean_squared_error: 0.8643 - val_loss: -37.1822 - val_mean_squared_error: 1.1753\n",
            "Epoch 180/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -52.9853 - mean_squared_error: 0.8640 - val_loss: -37.4836 - val_mean_squared_error: 1.1753\n",
            "Epoch 181/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -53.4892 - mean_squared_error: 0.8614 - val_loss: -37.8602 - val_mean_squared_error: 1.1737\n",
            "Epoch 182/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -54.0357 - mean_squared_error: 0.8626 - val_loss: -38.1365 - val_mean_squared_error: 1.1692\n",
            "Epoch 183/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -54.5837 - mean_squared_error: 0.8629 - val_loss: -38.5438 - val_mean_squared_error: 1.1747\n",
            "Epoch 184/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -55.3027 - mean_squared_error: 0.8629 - val_loss: -38.9737 - val_mean_squared_error: 1.1735\n",
            "Epoch 185/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -55.8514 - mean_squared_error: 0.8641 - val_loss: -39.5640 - val_mean_squared_error: 1.1787\n",
            "Epoch 186/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -56.4207 - mean_squared_error: 0.8641 - val_loss: -39.9257 - val_mean_squared_error: 1.1744\n",
            "Epoch 187/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -56.9588 - mean_squared_error: 0.8644 - val_loss: -40.3376 - val_mean_squared_error: 1.1757\n",
            "Epoch 188/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -57.5337 - mean_squared_error: 0.8629 - val_loss: -40.6950 - val_mean_squared_error: 1.1740\n",
            "Epoch 189/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -58.0297 - mean_squared_error: 0.8637 - val_loss: -41.1883 - val_mean_squared_error: 1.1738\n",
            "Epoch 190/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -58.6095 - mean_squared_error: 0.8626 - val_loss: -41.5374 - val_mean_squared_error: 1.1749\n",
            "Epoch 191/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -59.1342 - mean_squared_error: 0.8626 - val_loss: -42.0526 - val_mean_squared_error: 1.1747\n",
            "Epoch 192/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -59.7289 - mean_squared_error: 0.8655 - val_loss: -42.3772 - val_mean_squared_error: 1.1709\n",
            "Epoch 193/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -60.2831 - mean_squared_error: 0.8657 - val_loss: -42.7173 - val_mean_squared_error: 1.1690\n",
            "Epoch 194/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -60.8647 - mean_squared_error: 0.8654 - val_loss: -43.1725 - val_mean_squared_error: 1.1688\n",
            "Epoch 195/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -61.3952 - mean_squared_error: 0.8651 - val_loss: -43.5733 - val_mean_squared_error: 1.1702\n",
            "Epoch 196/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -61.9458 - mean_squared_error: 0.8660 - val_loss: -44.0672 - val_mean_squared_error: 1.1706\n",
            "Epoch 197/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -62.5524 - mean_squared_error: 0.8651 - val_loss: -44.4855 - val_mean_squared_error: 1.1693\n",
            "Epoch 198/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -63.1423 - mean_squared_error: 0.8658 - val_loss: -44.9063 - val_mean_squared_error: 1.1707\n",
            "Epoch 199/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -63.7233 - mean_squared_error: 0.8650 - val_loss: -45.3389 - val_mean_squared_error: 1.1720\n",
            "Epoch 200/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -64.2728 - mean_squared_error: 0.8620 - val_loss: -45.7382 - val_mean_squared_error: 1.1686\n",
            "Epoch 201/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -64.9427 - mean_squared_error: 0.8659 - val_loss: -46.3992 - val_mean_squared_error: 1.1705\n",
            "Epoch 202/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -65.6461 - mean_squared_error: 0.8703 - val_loss: -46.7821 - val_mean_squared_error: 1.1688\n",
            "Epoch 203/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -66.3219 - mean_squared_error: 0.8679 - val_loss: -47.1824 - val_mean_squared_error: 1.1681\n",
            "Epoch 204/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -66.8951 - mean_squared_error: 0.8646 - val_loss: -47.5365 - val_mean_squared_error: 1.1669\n",
            "Epoch 205/250\n",
            "35/35 [==============================] - 0s 7ms/step - loss: -67.4696 - mean_squared_error: 0.8640 - val_loss: -47.9876 - val_mean_squared_error: 1.1680\n",
            "Epoch 206/250\n",
            "35/35 [==============================] - 0s 7ms/step - loss: -68.0606 - mean_squared_error: 0.8619 - val_loss: -48.4537 - val_mean_squared_error: 1.1682\n",
            "Epoch 207/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -68.6430 - mean_squared_error: 0.8627 - val_loss: -48.8805 - val_mean_squared_error: 1.1675\n",
            "Epoch 208/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -69.2507 - mean_squared_error: 0.8643 - val_loss: -49.3666 - val_mean_squared_error: 1.1677\n",
            "Epoch 209/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -69.8352 - mean_squared_error: 0.8668 - val_loss: -49.9197 - val_mean_squared_error: 1.1698\n",
            "Epoch 210/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -70.4598 - mean_squared_error: 0.8628 - val_loss: -50.2727 - val_mean_squared_error: 1.1680\n",
            "Epoch 211/250\n",
            "35/35 [==============================] - 0s 7ms/step - loss: -71.0831 - mean_squared_error: 0.8665 - val_loss: -50.7813 - val_mean_squared_error: 1.1679\n",
            "Epoch 212/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -71.7083 - mean_squared_error: 0.8676 - val_loss: -51.2709 - val_mean_squared_error: 1.1679\n",
            "Epoch 213/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -72.3027 - mean_squared_error: 0.8643 - val_loss: -51.7010 - val_mean_squared_error: 1.1674\n",
            "Epoch 214/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -72.9406 - mean_squared_error: 0.8674 - val_loss: -52.2332 - val_mean_squared_error: 1.1666\n",
            "Epoch 215/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -73.5307 - mean_squared_error: 0.8697 - val_loss: -52.6532 - val_mean_squared_error: 1.1670\n",
            "Epoch 216/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -74.1765 - mean_squared_error: 0.8623 - val_loss: -52.9936 - val_mean_squared_error: 1.1662\n",
            "Epoch 217/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -74.8554 - mean_squared_error: 0.8666 - val_loss: -53.6186 - val_mean_squared_error: 1.1673\n",
            "Epoch 218/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -75.4468 - mean_squared_error: 0.8654 - val_loss: -54.1000 - val_mean_squared_error: 1.1664\n",
            "Epoch 219/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -76.1654 - mean_squared_error: 0.8662 - val_loss: -54.5706 - val_mean_squared_error: 1.1666\n",
            "Epoch 220/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -76.7618 - mean_squared_error: 0.8697 - val_loss: -55.1518 - val_mean_squared_error: 1.1654\n",
            "Epoch 221/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -77.4077 - mean_squared_error: 0.8708 - val_loss: -55.6093 - val_mean_squared_error: 1.1644\n",
            "Epoch 222/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -78.0776 - mean_squared_error: 0.8709 - val_loss: -56.0879 - val_mean_squared_error: 1.1634\n",
            "Epoch 223/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -78.6791 - mean_squared_error: 0.8719 - val_loss: -56.7005 - val_mean_squared_error: 1.1629\n",
            "Epoch 224/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -79.4112 - mean_squared_error: 0.8709 - val_loss: -57.0569 - val_mean_squared_error: 1.1623\n",
            "Epoch 225/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -80.0590 - mean_squared_error: 0.8685 - val_loss: -57.4982 - val_mean_squared_error: 1.1612\n",
            "Epoch 226/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -80.6854 - mean_squared_error: 0.8695 - val_loss: -57.9598 - val_mean_squared_error: 1.1617\n",
            "Epoch 227/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -81.4083 - mean_squared_error: 0.8663 - val_loss: -58.3555 - val_mean_squared_error: 1.1610\n",
            "Epoch 228/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -82.0179 - mean_squared_error: 0.8656 - val_loss: -58.8575 - val_mean_squared_error: 1.1599\n",
            "Epoch 229/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -82.6772 - mean_squared_error: 0.8623 - val_loss: -59.2893 - val_mean_squared_error: 1.1598\n",
            "Epoch 230/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -83.4167 - mean_squared_error: 0.8635 - val_loss: -59.7776 - val_mean_squared_error: 1.1587\n",
            "Epoch 231/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -84.0336 - mean_squared_error: 0.8670 - val_loss: -60.3102 - val_mean_squared_error: 1.1572\n",
            "Epoch 232/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -84.7374 - mean_squared_error: 0.8678 - val_loss: -60.7329 - val_mean_squared_error: 1.1567\n",
            "Epoch 233/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -85.4569 - mean_squared_error: 0.8699 - val_loss: -61.4373 - val_mean_squared_error: 1.1579\n",
            "Epoch 234/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -86.1894 - mean_squared_error: 0.8675 - val_loss: -61.8340 - val_mean_squared_error: 1.1572\n",
            "Epoch 235/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -86.8837 - mean_squared_error: 0.8675 - val_loss: -62.4408 - val_mean_squared_error: 1.1577\n",
            "Epoch 236/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -87.5811 - mean_squared_error: 0.8685 - val_loss: -63.0154 - val_mean_squared_error: 1.1600\n",
            "Epoch 237/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -88.2448 - mean_squared_error: 0.8689 - val_loss: -63.4448 - val_mean_squared_error: 1.1602\n",
            "Epoch 238/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -88.9663 - mean_squared_error: 0.8670 - val_loss: -63.9968 - val_mean_squared_error: 1.1606\n",
            "Epoch 239/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -89.6294 - mean_squared_error: 0.8657 - val_loss: -64.3815 - val_mean_squared_error: 1.1592\n",
            "Epoch 240/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -90.4383 - mean_squared_error: 0.8673 - val_loss: -64.9150 - val_mean_squared_error: 1.1598\n",
            "Epoch 241/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -91.1001 - mean_squared_error: 0.8690 - val_loss: -65.5753 - val_mean_squared_error: 1.1591\n",
            "Epoch 242/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -91.8620 - mean_squared_error: 0.8692 - val_loss: -66.0169 - val_mean_squared_error: 1.1595\n",
            "Epoch 243/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -92.5265 - mean_squared_error: 0.8667 - val_loss: -66.5353 - val_mean_squared_error: 1.1589\n",
            "Epoch 244/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -93.2684 - mean_squared_error: 0.8663 - val_loss: -66.9413 - val_mean_squared_error: 1.1569\n",
            "Epoch 245/250\n",
            "35/35 [==============================] - 0s 6ms/step - loss: -93.9962 - mean_squared_error: 0.8685 - val_loss: -67.5915 - val_mean_squared_error: 1.1584\n",
            "Epoch 246/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -94.7767 - mean_squared_error: 0.8710 - val_loss: -68.3341 - val_mean_squared_error: 1.1584\n",
            "Epoch 247/250\n",
            "35/35 [==============================] - 0s 5ms/step - loss: -95.5878 - mean_squared_error: 0.8690 - val_loss: -68.8721 - val_mean_squared_error: 1.1581\n",
            "Epoch 248/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -96.2356 - mean_squared_error: 0.8660 - val_loss: -69.3286 - val_mean_squared_error: 1.1576\n",
            "Epoch 249/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -97.0207 - mean_squared_error: 0.8691 - val_loss: -69.8930 - val_mean_squared_error: 1.1560\n",
            "Epoch 250/250\n",
            "35/35 [==============================] - 0s 4ms/step - loss: -97.6808 - mean_squared_error: 0.8717 - val_loss: -70.3903 - val_mean_squared_error: 1.1567\n",
            "16/16 [==============================] - 0s 2ms/step - loss: -89.0655 - mean_squared_error: 0.9643\n",
            "mean_squared_error: 96.43%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'mean_squared_error', 'val_loss', 'val_mean_squared_error'])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "hcNoqkr2mOjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history[\"mean_squared_error\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"model mean squared error\")\n",
        "plt.ylabel(\"mean_squared_error\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\",\"test\"],loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Pv5HIWremLSk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "44eaf87e-946b-4948-e0f9-b1a1eb0370df"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We obtained the best possible and acceptable accuracy with the keras classifier."
      ],
      "metadata": {
        "id": "2t4gI8G1mTyY"
      }
    }
  ]
}